"use strict";(self.webpackChunkrts_docs=self.webpackChunkrts_docs||[]).push([["954"],{81428(e,t,n){n.r(t),n.d(t,{metadata:()=>s,default:()=>h,frontMatter:()=>l,contentTitle:()=>a,toc:()=>d,assets:()=>c});var s=JSON.parse('{"id":"hpc/ml_ai_hpc/tensorflow","title":"TensorFlow","description":"This was adapted from Princeton University Multi-GPU Training with PyTorch","source":"@site/docs/hpc/08_ml_ai_hpc/04_tensorflow.md","sourceDirName":"hpc/08_ml_ai_hpc","slug":"/hpc/ml_ai_hpc/tensorflow","permalink":"/docs/hpc/ml_ai_hpc/tensorflow","draft":false,"unlisted":false,"editUrl":"https://github.com/NYU-RTS/rts-docs/blob/main/docs/hpc/08_ml_ai_hpc/04_tensorflow.md","tags":[],"version":"current","sidebarPosition":4,"frontMatter":{},"sidebar":"hpcSidebar","previous":{"title":"Multi-GPU Training with PyTorch: Distributed Data Parallel (DDP)","permalink":"/docs/hpc/ml_ai_hpc/pytorch_dpp"},"next":{"title":"Fine tune LLMs on HPC","permalink":"/docs/hpc/ml_ai_hpc/llm_fine_tuning"}}'),i=n(62615),r=n(30416);let l={},a="TensorFlow",c={},d=[{value:"Single-Node, Synchronous, Multi-GPU Training",id:"single-node-synchronous-multi-gpu-training",level:2},{value:"Step 1: Create a TensorFlow Overlay File",id:"step-1-create-a-tensorflow-overlay-file",level:3},{value:"Step 2: Download the Data",id:"step-2-download-the-data",level:3},{value:"Step 3: Inspect the Script",id:"step-3-inspect-the-script",level:3},{value:"Step 4: Submit the Job",id:"step-4-submit-the-job",level:3},{value:"Performance",id:"performance",level:3},{value:"Multi-node Training",id:"multi-node-training",level:2}];function o(e){let t={a:"a",admonition:"admonition",code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",img:"img",li:"li",p:"p",pre:"pre",table:"table",tbody:"tbody",td:"td",th:"th",thead:"thead",tr:"tr",ul:"ul",...(0,r.R)(),...e.components};return(0,i.jsxs)(i.Fragment,{children:[(0,i.jsx)(t.header,{children:(0,i.jsx)(t.h1,{id:"tensorflow",children:"TensorFlow"})}),"\n",(0,i.jsx)(t.admonition,{type:"info",children:(0,i.jsxs)(t.p,{children:["This was adapted from ",(0,i.jsx)(t.a,{href:"https://github.com/PrincetonUniversity/multi_gpu_training",children:"Princeton University Multi-GPU Training with PyTorch"})]})}),"\n",(0,i.jsxs)(t.p,{children:["The starting point for ",(0,i.jsx)(t.a,{href:"https://www.tensorflow.org/tutorials/distribute/keras",children:"multi-GPU training with Keras"})," is ",(0,i.jsx)(t.code,{children:"tf.distribute.MirroredStrategy"}),". In this approach, the model is copied to ",(0,i.jsx)(t.code,{children:"N"})," GPUs and gradients are synced as we saw previously. Be sure to use ",(0,i.jsx)(t.a,{href:"https://www.tensorflow.org/api_docs/python/tf/data",children:(0,i.jsx)(t.code,{children:"tf.data"})})," to handle data loading as is done in the example on this page and is explained graphically ",(0,i.jsx)(t.a,{href:"https://colab.research.google.com/github/tensorflow/docs/blob/master/site/en/guide/data_performance.ipynb#scrollTo=i3NtGI3r-jLp",children:"here"}),"."]}),"\n",(0,i.jsx)(t.h2,{id:"single-node-synchronous-multi-gpu-training",children:"Single-Node, Synchronous, Multi-GPU Training"}),"\n",(0,i.jsxs)(t.p,{children:["Here were train the ResNet-50 model on the Cassava dataset (see ",(0,i.jsx)(t.a,{href:"https://www.youtube.com/watch?v=xzSCvXDcX68",children:"video"})," on TensorFlow YouTube channel). Here is another example ",(0,i.jsx)(t.a,{href:"https://www.youtube.com/watch?v=HCLmM1PyDIs",children:"video"}),' using the "cats vs. dog" dataset.']}),"\n",(0,i.jsx)(t.h3,{id:"step-1-create-a-tensorflow-overlay-file",children:"Step 1: Create a TensorFlow Overlay File"}),"\n",(0,i.jsx)(t.pre,{children:(0,i.jsx)(t.code,{className:"language-bash",children:"# create a working directory\n[NetID@log-1 ~]$ mkdir /scratch/<NetID>/tensorflow-example\n[NetID@log-1 ~]$ cd /scratch/<NetID>/tensorflow-example\n\n# copy over an overlay file with sufficient resources and unzip it\n[NetID@cm001 tensorflow-example]$ cp -rp /scratch/work/public/overlay-fs-ext3/overlay-15GB-500K.ext3.gz .\n[NetID@cm001 tensorflow-example]$ gunzip overlay-15GB-500K.ext3.gz\n\n# start the singularity environment\n[NetID@cm001 tensorflow-example]$ singularity exec --overlay overlay-15GB-500K.ext3:rw /scratch/work/public/singularity/cuda12.1.1-cudnn8.9.0-devel-ubuntu22.04.2.sif /bin/bash\n\n# install miniforge in singularity environment\nSingularity> wget --no-check-certificate https://github.com/conda-forge/miniforge/releases/latest/download/Miniforge3-Linux-x86_64.sh\nSingularity> bash Miniforge3-Linux-x86_64.sh -b -p /ext3/miniforge3\n\n# create an miniconda environment file \nSingularity> touch /ext3/env.sh\nSingularity> nano /ext3/env.sh\n# and add the following content to it:\n"})}),"\n",(0,i.jsx)(t.pre,{children:(0,i.jsx)(t.code,{className:"language-bash",children:"#!/bin/bash\n\nunset -f which\n\nsource /ext3/miniforge3/etc/profile.d/conda.sh\nexport PATH=/ext3/miniforge3/bin:$PATH\nexport PYTHONPATH=/ext3/miniforge3/bin:$PATH\n"})}),"\n",(0,i.jsx)(t.pre,{children:(0,i.jsx)(t.code,{className:"language-bash",children:"# activate the new environment and initialize\nSingularity> source /ext3/env.sh \nSingularity> conda config --remove channels defaults\nSingularity> conda clean --all --yes\nSingularity> conda update -n base conda -y\nSingularity> conda install pip -y\nSingularity> conda install ipykernel -y\n\n# check that you're using the miniconda environment\n# you should get the following output\nSingularity> which conda\n/ext3/miniforge3/bin/conda\nSingularity> which python\n/ext3/miniforge3/bin/python\nSingularity> which pip\n/ext3/miniforge3/bin/pip\n\n# install TensorFlow\nSingularity> pip install tensorflow[and-cuda] tensorflow_datasets\n"})}),"\n",(0,i.jsx)(t.h3,{id:"step-2-download-the-data",children:"Step 2: Download the Data"}),"\n",(0,i.jsxs)(t.p,{children:["This example using the ",(0,i.jsx)(t.code,{children:"cassava"})," dataset which requires 4 GB of storage space. Be sure to save this in your ",(0,i.jsx)(t.code,{children:"/scratch"})," space and not in ",(0,i.jsx)(t.code,{children:"/home"}),"."]}),"\n",(0,i.jsxs)(t.p,{children:["Please save the following into a file named ",(0,i.jsx)(t.code,{children:"download_data_and_weights.py"}),":"]}),"\n",(0,i.jsx)(t.pre,{children:(0,i.jsx)(t.code,{className:"language-python",children:"import tensorflow as tf\nimport tensorflow_datasets as tfds\n\n# download the data (4 GB) on the login node\n_ = tfds.load(name='cassava', with_info=True, as_supervised=True, data_dir='.')\n\n# download the model weights on the login node\n_ = tf.keras.applications.ResNet50(weights=\"imagenet\", include_top=False)\n"})}),"\n",(0,i.jsx)(t.p,{children:"Run the command below to download the data (4 GB in size):"}),"\n",(0,i.jsx)(t.pre,{children:(0,i.jsx)(t.code,{className:"language-bash",children:'# switch to a data transfer node\n[NetID@log-1 tensorflow_example]$ ssh gdtn\n[NetID@dtn-1 ~]$ cd /scratch/NetID/tensorflow_example\n[NetID@dtn-1 tensorflow_example]$ singularity exec --nv --overlay /scratch/NetID/pytorch-example/my_pytorch.ext3:ro /scratch/work/public/singularity/cuda12.1.1-cudnn8.9.0-devel-ubuntu22.04.2.sif /bin/bash -c "source /ext3/env.sh; python download_data_and_weights.py"\n'})}),"\n",(0,i.jsx)(t.h3,{id:"step-3-inspect-the-script",children:"Step 3: Inspect the Script"}),"\n",(0,i.jsxs)(t.p,{children:["Below is the contents of ",(0,i.jsx)(t.code,{children:"mnist_classify.py"}),":"]}),"\n",(0,i.jsx)(t.pre,{children:(0,i.jsx)(t.code,{className:"language-python",children:"import argparse\nimport os\nimport tensorflow_datasets as tfds\nimport tensorflow as tf\nfrom time import perf_counter\n\ndef preprocess_data(image, label):\n  image = tf.image.resize(image, (300, 300))\n  image = tf.cast(image, tf.float32) / 255.0\n  return image, label\n\ndef create_dataset(batch_size_per_replica, datasets, strategy):\n  batch_size = batch_size_per_replica * strategy.num_replicas_in_sync\n  return datasets['train'].map(preprocess_data, num_parallel_calls=tf.data.AUTOTUNE) \\\n                          .cache() \\\n                          .shuffle(1000) \\\n                          .batch(batch_size) \\\n                          .prefetch(tf.data.AUTOTUNE)\n\ndef create_model(num_classes):\n  base_model = tf.keras.applications.ResNet50(weights=\"imagenet\", include_top=False)\n  x = base_model.output\n  x = tf.keras.layers.GlobalAveragePooling2D()(x)\n  x = tf.keras.layers.Dense(1016, activation=\"relu\")(x)\n  predictions = tf.keras.layers.Dense(num_classes, activation=\"softmax\")(x)\n  model = tf.keras.Model(inputs=base_model.input, outputs=predictions)\n  return model\n\ndef train(epochs, num_classes, train_dataset, strategy):\n  with strategy.scope():\n    model = create_model(num_classes)\n    model.compile(loss='sparse_categorical_crossentropy',\n                  optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001),\n                  metrics=['accuracy'])\n\n  start_time = perf_counter()\n  model.fit(train_dataset, epochs=epochs)\n  print(\"Training time:\", perf_counter() - start_time)\n  return None\n\ndef print_info(num_replicas_in_sync, batch_size_per_replica, info, num_classes):\n  print(f'TF Version: {tf.__version__}')\n  print(f'Number of GPUs: {num_replicas_in_sync}')\n  print(f'Batch size per GPU: {batch_size_per_replica}')\n  print(f'Train records: {info.splits[\"train\"].num_examples}')\n  print(f'Test records:  {info.splits[\"test\"].num_examples}')\n  print(f'Number of classes: {num_classes}')\n  return None\n\nif __name__ == '__main__':\n  parser = argparse.ArgumentParser(description='Multi-GPU Training Example')\n  parser.add_argument('--batch-size-per-replica', type=int, default=32, metavar='N',\n                      help='input batch size per GPU for training (default: 32)')\n  parser.add_argument('--epochs', type=int, default=15, metavar='N',\n                      help='number of epochs to train (default: 15)')\n  args = parser.parse_args()\n  \n  datasets, info = tfds.load(name='cassava', with_info=True, as_supervised=True, data_dir=\".\")\n  num_classes = info.features[\"label\"].num_classes\n\n  strategy = tf.distribute.MirroredStrategy()\n  train_dataset = create_dataset(args.batch_size_per_replica, datasets, strategy)\n  train(args.epochs, num_classes, train_dataset, strategy)\n  \n  print_info(strategy.num_replicas_in_sync, args.batch_size_per_replica, info, num_classes)\n"})}),"\n",(0,i.jsx)(t.h3,{id:"step-4-submit-the-job",children:"Step 4: Submit the Job"}),"\n",(0,i.jsx)(t.p,{children:"Below is a sample Slurm script:"}),"\n",(0,i.jsx)(t.pre,{children:(0,i.jsx)(t.code,{className:"language-bash",children:'#!/bin/bash\n#SBATCH --job-name=cassava       # create a short name for your job\n#SBATCH --nodes=1                # node count\n#SBATCH --ntasks=1               # total number of tasks across all nodes\n#SBATCH --cpus-per-task=16       # cpu-cores per task (>1 if multi-threaded tasks)\n#SBATCH --mem=64G                # total memory per node (4G per cpu-core is default)\n#SBATCH --gres=gpu:2             # number of gpus per node\n#SBATCH --time=00:20:00          # total run time limit (HH:MM:SS)\n\nmodule purge\n\nsrun singularity exec --nv \\\n	    --overlay /scratch/NetID/pytorch_examples_new/tensorflow-example/tensorflow.ext3:ro \\\n	    /scratch/work/public/singularity/cuda12.1.1-cudnn8.9.0-devel-ubuntu22.04.2.sif\\\n	    /bin/bash -c "source /ext3/env.sh; python mnist_classify.py --batch-size-per-replica=32 --epochs=15"\n'})}),"\n",(0,i.jsx)(t.admonition,{type:"note",children:(0,i.jsxs)(t.p,{children:["Be sure to change ",(0,i.jsx)(t.code,{children:"NetID"})," in the above script to your NetID."]})}),"\n",(0,i.jsx)(t.p,{children:"Submit the job as follows:"}),"\n",(0,i.jsx)(t.pre,{children:(0,i.jsx)(t.code,{className:"language-bash",children:"[NetID@log-1 tensorflow_example]$ sbatch job.slurm\n"})}),"\n",(0,i.jsx)(t.h3,{id:"performance",children:"Performance"}),"\n",(0,i.jsxs)(t.p,{children:["The training time is shown below for different choices of ",(0,i.jsx)(t.code,{children:"cpus-per-task"})," and the number of GPUs on a test system (your results will vary depending on your system specs):"]}),"\n",(0,i.jsxs)(t.table,{children:[(0,i.jsx)(t.thead,{children:(0,i.jsxs)(t.tr,{children:[(0,i.jsx)(t.th,{style:{textAlign:"center"},children:"nodes"}),(0,i.jsx)(t.th,{style:{textAlign:"center"},children:"ntasks"}),(0,i.jsx)(t.th,{style:{textAlign:"center"},children:"cpus-per-task"}),(0,i.jsx)(t.th,{style:{textAlign:"center"},children:"GPUs"}),(0,i.jsx)(t.th,{style:{textAlign:"center"},children:"Training Time (s)"}),(0,i.jsx)(t.th,{style:{textAlign:"center"},children:"Mean GPU Utilization (%)"})]})}),(0,i.jsxs)(t.tbody,{children:[(0,i.jsxs)(t.tr,{children:[(0,i.jsx)(t.td,{style:{textAlign:"center"},children:"1"}),(0,i.jsx)(t.td,{style:{textAlign:"center"},children:"1"}),(0,i.jsx)(t.td,{style:{textAlign:"center"},children:"2"}),(0,i.jsx)(t.td,{style:{textAlign:"center"},children:"1"}),(0,i.jsx)(t.td,{style:{textAlign:"center"},children:"574"}),(0,i.jsx)(t.td,{style:{textAlign:"center"},children:"85"})]}),(0,i.jsxs)(t.tr,{children:[(0,i.jsx)(t.td,{style:{textAlign:"center"},children:"1"}),(0,i.jsx)(t.td,{style:{textAlign:"center"},children:"1"}),(0,i.jsx)(t.td,{style:{textAlign:"center"},children:"4"}),(0,i.jsx)(t.td,{style:{textAlign:"center"},children:"1"}),(0,i.jsx)(t.td,{style:{textAlign:"center"},children:"565"}),(0,i.jsx)(t.td,{style:{textAlign:"center"},children:"83"})]}),(0,i.jsxs)(t.tr,{children:[(0,i.jsx)(t.td,{style:{textAlign:"center"},children:"1"}),(0,i.jsx)(t.td,{style:{textAlign:"center"},children:"1"}),(0,i.jsx)(t.td,{style:{textAlign:"center"},children:"8"}),(0,i.jsx)(t.td,{style:{textAlign:"center"},children:"1"}),(0,i.jsx)(t.td,{style:{textAlign:"center"},children:"562"}),(0,i.jsx)(t.td,{style:{textAlign:"center"},children:"89"})]}),(0,i.jsxs)(t.tr,{children:[(0,i.jsx)(t.td,{style:{textAlign:"center"},children:"1"}),(0,i.jsx)(t.td,{style:{textAlign:"center"},children:"1"}),(0,i.jsx)(t.td,{style:{textAlign:"center"},children:"16"}),(0,i.jsx)(t.td,{style:{textAlign:"center"},children:"1"}),(0,i.jsx)(t.td,{style:{textAlign:"center"},children:"564"}),(0,i.jsx)(t.td,{style:{textAlign:"center"},children:"90"})]}),(0,i.jsxs)(t.tr,{children:[(0,i.jsx)(t.td,{style:{textAlign:"center"},children:"1"}),(0,i.jsx)(t.td,{style:{textAlign:"center"},children:"1"}),(0,i.jsx)(t.td,{style:{textAlign:"center"},children:"4"}),(0,i.jsx)(t.td,{style:{textAlign:"center"},children:"2"}),(0,i.jsx)(t.td,{style:{textAlign:"center"},children:"339"}),(0,i.jsx)(t.td,{style:{textAlign:"center"},children:"76"})]}),(0,i.jsxs)(t.tr,{children:[(0,i.jsx)(t.td,{style:{textAlign:"center"},children:"1"}),(0,i.jsx)(t.td,{style:{textAlign:"center"},children:"1"}),(0,i.jsx)(t.td,{style:{textAlign:"center"},children:"8"}),(0,i.jsx)(t.td,{style:{textAlign:"center"},children:"2"}),(0,i.jsx)(t.td,{style:{textAlign:"center"},children:"334"}),(0,i.jsx)(t.td,{style:{textAlign:"center"},children:"81"})]}),(0,i.jsxs)(t.tr,{children:[(0,i.jsx)(t.td,{style:{textAlign:"center"},children:"1"}),(0,i.jsx)(t.td,{style:{textAlign:"center"},children:"1"}),(0,i.jsx)(t.td,{style:{textAlign:"center"},children:"16"}),(0,i.jsx)(t.td,{style:{textAlign:"center"},children:"2"}),(0,i.jsx)(t.td,{style:{textAlign:"center"},children:"332"}),(0,i.jsx)(t.td,{style:{textAlign:"center"},children:"74"})]}),(0,i.jsxs)(t.tr,{children:[(0,i.jsx)(t.td,{style:{textAlign:"center"},children:"1"}),(0,i.jsx)(t.td,{style:{textAlign:"center"},children:"1"}),(0,i.jsx)(t.td,{style:{textAlign:"center"},children:"4"}),(0,i.jsx)(t.td,{style:{textAlign:"center"},children:"3"}),(0,i.jsx)(t.td,{style:{textAlign:"center"},children:"256"}),(0,i.jsx)(t.td,{style:{textAlign:"center"},children:"68"})]}),(0,i.jsxs)(t.tr,{children:[(0,i.jsx)(t.td,{style:{textAlign:"center"},children:"1"}),(0,i.jsx)(t.td,{style:{textAlign:"center"},children:"1"}),(0,i.jsx)(t.td,{style:{textAlign:"center"},children:"8"}),(0,i.jsx)(t.td,{style:{textAlign:"center"},children:"3"}),(0,i.jsx)(t.td,{style:{textAlign:"center"},children:"251"}),(0,i.jsx)(t.td,{style:{textAlign:"center"},children:"73"})]}),(0,i.jsxs)(t.tr,{children:[(0,i.jsx)(t.td,{style:{textAlign:"center"},children:"1"}),(0,i.jsx)(t.td,{style:{textAlign:"center"},children:"1"}),(0,i.jsx)(t.td,{style:{textAlign:"center"},children:"16"}),(0,i.jsx)(t.td,{style:{textAlign:"center"},children:"3"}),(0,i.jsx)(t.td,{style:{textAlign:"center"},children:"249"}),(0,i.jsx)(t.td,{style:{textAlign:"center"},children:"66"})]}),(0,i.jsxs)(t.tr,{children:[(0,i.jsx)(t.td,{style:{textAlign:"center"},children:"1"}),(0,i.jsx)(t.td,{style:{textAlign:"center"},children:"1"}),(0,i.jsx)(t.td,{style:{textAlign:"center"},children:"4"}),(0,i.jsx)(t.td,{style:{textAlign:"center"},children:"4"}),(0,i.jsx)(t.td,{style:{textAlign:"center"},children:"226"}),(0,i.jsx)(t.td,{style:{textAlign:"center"},children:"59"})]}),(0,i.jsxs)(t.tr,{children:[(0,i.jsx)(t.td,{style:{textAlign:"center"},children:"1"}),(0,i.jsx)(t.td,{style:{textAlign:"center"},children:"1"}),(0,i.jsx)(t.td,{style:{textAlign:"center"},children:"8"}),(0,i.jsx)(t.td,{style:{textAlign:"center"},children:"4"}),(0,i.jsx)(t.td,{style:{textAlign:"center"},children:"220"}),(0,i.jsx)(t.td,{style:{textAlign:"center"},children:"58"})]}),(0,i.jsxs)(t.tr,{children:[(0,i.jsx)(t.td,{style:{textAlign:"center"},children:"1"}),(0,i.jsx)(t.td,{style:{textAlign:"center"},children:"1"}),(0,i.jsx)(t.td,{style:{textAlign:"center"},children:"16"}),(0,i.jsx)(t.td,{style:{textAlign:"center"},children:"4"}),(0,i.jsx)(t.td,{style:{textAlign:"center"},children:"214"}),(0,i.jsx)(t.td,{style:{textAlign:"center"},children:"65"})]}),(0,i.jsxs)(t.tr,{children:[(0,i.jsx)(t.td,{style:{textAlign:"center"},children:"1"}),(0,i.jsx)(t.td,{style:{textAlign:"center"},children:"1"}),(0,i.jsx)(t.td,{style:{textAlign:"center"},children:"32"}),(0,i.jsx)(t.td,{style:{textAlign:"center"},children:"4"}),(0,i.jsx)(t.td,{style:{textAlign:"center"},children:"218"}),(0,i.jsx)(t.td,{style:{textAlign:"center"},children:"63"})]})]})]}),"\n",(0,i.jsxs)(t.p,{children:['"Training Time" in the table above is the time to run ',(0,i.jsx)(t.code,{children:"model.fit(train_dataset, epochs=epochs)"}),'. "Mean GPU utilization" was taken from the output of the ',(0,i.jsx)(t.code,{children:"jobstats"})," command."]}),"\n",(0,i.jsx)(t.p,{children:"The figure below shows the speed-up as a function of the number of GPUs. The dashed line shows the maximum possible speed-up."}),"\n",(0,i.jsx)(t.p,{children:(0,i.jsx)(t.img,{alt:"speedup vs gpus plot",src:n(86962).A+"",width:"1000",height:"600"})}),"\n",(0,i.jsx)(t.p,{children:"We see that linear scaling is not observed. That is, the training time when using 2 GPUs is not 1/2 of the training time when using one. To improve on this one would profile the script and identify the performance bottleneck. Some of the training images are 500 pixels wide. It could be that the preprocessing step is the slowest."}),"\n",(0,i.jsx)(t.h2,{id:"multi-node-training",children:"Multi-node Training"}),"\n",(0,i.jsxs)(t.ul,{children:["\n",(0,i.jsxs)(t.li,{children:[(0,i.jsx)(t.a,{href:"https://www.tensorflow.org/guide/distributed_training#multiworkermirroredstrategy",children:"MultiWorkerMirroredStrategy"})," for using the GPUs on more than one compute node."]}),"\n",(0,i.jsxs)(t.li,{children:[(0,i.jsx)(t.a,{href:"https://www.tensorflow.org/tutorials/distribute/multi_worker_with_keras",children:"Keras API"}),"."]}),"\n",(0,i.jsxs)(t.li,{children:[(0,i.jsx)(t.a,{href:"https://horovod.ai/",children:"Horovod"})," is a distributed deep learning training framework for TensorFlow, Keras, PyTorch, and Apache MXNet. It is based on MPI."]}),"\n"]})]})}function h(e={}){let{wrapper:t}={...(0,r.R)(),...e.components};return t?(0,i.jsx)(t,{...e,children:(0,i.jsx)(o,{...e})}):o(e)}},86962(e,t,n){n.d(t,{A:()=>s});let s=n.p+"assets/images/speedup_vs_gpus-4fda8a5563c539377160afb94ba97b6d.png"},30416(e,t,n){n.d(t,{R:()=>l,x:()=>a});var s=n(59471);let i={},r=s.createContext(i);function l(e){let t=s.useContext(r);return s.useMemo(function(){return"function"==typeof e?e(t):{...t,...e}},[t,e])}function a(e){let t;return t=e.disableParentContext?"function"==typeof e.components?e.components(i):e.components||i:l(e.components),s.createElement(r.Provider,{value:t},e.children)}}}]);