"use strict";(self.webpackChunkrts_docs=self.webpackChunkrts_docs||[]).push([["3427"],{57667(e,n,i){i.r(n),i.d(n,{metadata:()=>t,default:()=>d,frontMatter:()=>s,contentTitle:()=>a,toc:()=>l,assets:()=>c});var t=JSON.parse('{"id":"hpc/ml_ai_hpc/intro","title":"Machine Learning (ML) and Artificial Intelligence (AI) on HPC","description":"Many people are interested in running ML and/or AI workflows on the HPC resources.  To help facilitate this we have created this section that will provide examples of how one might use our resources for ML and AI tasks.","source":"@site/docs/hpc/08_ml_ai_hpc/01_intro.md","sourceDirName":"hpc/08_ml_ai_hpc","slug":"/hpc/ml_ai_hpc/intro","permalink":"/docs/hpc/ml_ai_hpc/intro","draft":false,"unlisted":false,"editUrl":"https://github.com/NYU-RTS/rts-docs/blob/main/docs/hpc/08_ml_ai_hpc/01_intro.md","tags":[],"version":"current","sidebarPosition":1,"frontMatter":{},"sidebar":"hpcSidebar","previous":{"title":"Squash File System and Singularity","permalink":"/docs/hpc/containers/squash_file_system_and_singularity"},"next":{"title":"Single-GPU Training with PyTorch","permalink":"/docs/hpc/ml_ai_hpc/pytorch_intro"}}'),r=i(62615),o=i(30416);let s={},a="Machine Learning (ML) and Artificial Intelligence (AI) on HPC",c={},l=[];function h(e){let n={h1:"h1",header:"header",p:"p",strong:"strong",...(0,o.R)(),...e.components};return(0,r.jsxs)(r.Fragment,{children:[(0,r.jsx)(n.header,{children:(0,r.jsx)(n.h1,{id:"machine-learning-ml-and-artificial-intelligence-ai-on-hpc",children:"Machine Learning (ML) and Artificial Intelligence (AI) on HPC"})}),"\n",(0,r.jsx)(n.p,{children:"Many people are interested in running ML and/or AI workflows on the HPC resources.  To help facilitate this we have created this section that will provide examples of how one might use our resources for ML and AI tasks."}),"\n",(0,r.jsx)(n.p,{children:"For ML we'll cover two prominent open-source deep learning frameworks, PyTorch and TensorFlow.  We'll show how to start with a single GPU example and then show more sophisticated examples."}),"\n",(0,r.jsx)(n.p,{children:"For AI we'll cover how to run a Hugging Face Large Language Model (LLM) and how to fine tune an LLM. Specifically, we provide guides on:"}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"LLM Inference"}),": Use the standard Hugging Face transformers library for basic tasks, and also introduce vLLM, a high-throughput serving engine that offers faster inference and an OpenAI-compatible API."]}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"vLLM CLI"}),": We provide examples of using the vllm command-line tool to quickly serve models and engage in interactive chat sessions."]}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Fine-tuning LLMs"}),": We provide a practical example of fine-tuning the Gemma model to follow specific instructions. This section compares the original model with our improved version, showing how to achieve better response quality on Torch."]})]})}function d(e={}){let{wrapper:n}={...(0,o.R)(),...e.components};return n?(0,r.jsx)(n,{...e,children:(0,r.jsx)(h,{...e})}):h(e)}},30416(e,n,i){i.d(n,{R:()=>s,x:()=>a});var t=i(59471);let r={},o=t.createContext(r);function s(e){let n=t.useContext(o);return t.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function a(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(r):e.components||r:s(e.components),t.createElement(o.Provider,{value:n},e.children)}}}]);