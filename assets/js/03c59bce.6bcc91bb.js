"use strict";(self.webpackChunkrts_docs=self.webpackChunkrts_docs||[]).push([["4022"],{22242(e,n,t){t.r(n),t.d(n,{metadata:()=>i,default:()=>g,frontMatter:()=>r,contentTitle:()=>s,toc:()=>l,assets:()=>d});var i=JSON.parse('{"id":"genai/how_to_guides/embeddings","title":"Generating embeddings","description":"While Decoder-only LLMs gained massive popularity via their usage in chatbots, Encoder-only LLMs can be used for a wider variety of tasks. Decoder-only LLMs \\"generate\\" tokens (\\"text\\") one at a time probabalisticsally. Encoder-only LLMs on the other hand take text as their input, tokenize it and generate \\"embeddings\\" as their output. Here, we shall walk through a task of generating embeddings from a text snippet.","source":"@site/docs/genai/04_how_to_guides/02_embeddings.mdx","sourceDirName":"genai/04_how_to_guides","slug":"/genai/how_to_guides/embeddings","permalink":"/docs/genai/how_to_guides/embeddings","draft":false,"unlisted":false,"editUrl":"https://github.com/NYU-RTS/rts-docs/blob/main/docs/genai/04_how_to_guides/02_embeddings.mdx","tags":[],"version":"current","sidebarPosition":2,"frontMatter":{},"sidebar":"genaiSidebar","previous":{"title":"Effect of Temperature","permalink":"/docs/genai/how_to_guides/temperature"},"next":{"title":"Retrieval-augmented generation","permalink":"/docs/genai/how_to_guides/retrieval_augmented_generation"}}'),a=t(62615),o=t(30416);let r={},s="Generating embeddings",d={},l=[{value:"Applications of embeddings",id:"applications-of-embeddings",level:2}];function c(e){let n={admonition:"admonition",code:"code",em:"em",h1:"h1",h2:"h2",header:"header",li:"li",mermaid:"mermaid",p:"p",pre:"pre",ul:"ul",...(0,o.R)(),...e.components};return(0,a.jsxs)(a.Fragment,{children:[(0,a.jsx)(n.header,{children:(0,a.jsx)(n.h1,{id:"generating-embeddings",children:"Generating embeddings"})}),"\n",(0,a.jsx)(n.p,{children:'While Decoder-only LLMs gained massive popularity via their usage in chatbots, Encoder-only LLMs can be used for a wider variety of tasks. Decoder-only LLMs "generate" tokens ("text") one at a time probabalisticsally. Encoder-only LLMs on the other hand take text as their input, tokenize it and generate "embeddings" as their output. Here, we shall walk through a task of generating embeddings from a text snippet.'}),"\n",(0,a.jsx)(n.mermaid,{value:'flowchart LR;\n    A["natual language text: <br> *GenAI can be used for research*"]\n    B["encoder-only LLM"]\n    C["vector embedding <br> [0.052, 0.094, 0.244, ...]"]\n    A-- "Input" --\x3eB;\n    B-- "Output" --\x3eC;'}),"\n",(0,a.jsx)(n.admonition,{type:"tip",children:(0,a.jsx)(n.p,{children:"Embeddings have the ability to encode the semantic meaning of the natual language text/images!"})}),"\n",(0,a.jsxs)(n.p,{children:["The snippet below uses the ",(0,a.jsx)(n.code,{children:"text-embedding-3-small"})," model to create 32-dimensional floating point vector embeddings for the input string:"]}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:'from portkey_ai import Portkey\n\nportkey = Portkey(\n    base_url="https://ai-gateway.apps.cloud.rt.nyu.edu/v1/",\n    api_key="",  # Replace with your Portkey API key\n)\n\nresponse = portkey.embeddings.create(\n    model="@AI-Provider/text-embedding-3-small", # Replace with AI Provider from your workspace!\n    input="GenAI can be used for research.",\n    encoding_format="float",\n    dimensions=32,\n)\n\nprint(response["data"][0].embedding)\n'})}),"\n",(0,a.jsx)(n.p,{children:"and gives the following response:"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{children:"[0.052587852, 0.094195396, 0.24439038, 0.104940414, -0.028921358, -0.31591928, -0.1846261, 0.221018, 0.033215445, -0.1382735, -0.14776362, -0.15058714, 0.057725072, -0.23435123, 0.07956805, -0.32156628, -0.08454841, 0.04066637, -0.022215525, 0.19090058, -0.11160703, 0.22258662, -0.06843088, -0.22854735, 0.1033718, -0.38085997, 0.2933312, -0.023215517, 0.20768477, -0.039333045, 0.17192031, -0.14180289]\n"})}),"\n",(0,a.jsx)(n.h2,{id:"applications-of-embeddings",children:"Applications of embeddings"}),"\n",(0,a.jsx)(n.p,{children:"Embeddings are typically used for:"}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsx)(n.li,{children:"retrieval-augmented generation"}),"\n",(0,a.jsx)(n.li,{children:"search"}),"\n",(0,a.jsx)(n.li,{children:"classification"}),"\n"]}),"\n",(0,a.jsx)(n.admonition,{type:"info",children:(0,a.jsxs)(n.p,{children:["Embeddings are typically stored in a ",(0,a.jsx)(n.em,{children:"vector"})," database which is designed for efficient storage and fast retrieval of vectors."]})})]})}function g(e={}){let{wrapper:n}={...(0,o.R)(),...e.components};return n?(0,a.jsx)(n,{...e,children:(0,a.jsx)(c,{...e})}):c(e)}},30416(e,n,t){t.d(n,{R:()=>r,x:()=>s});var i=t(59471);let a={},o=i.createContext(a);function r(e){let n=i.useContext(o);return i.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function s(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(a):e.components||a:r(e.components),i.createElement(o.Provider,{value:n},e.children)}}}]);