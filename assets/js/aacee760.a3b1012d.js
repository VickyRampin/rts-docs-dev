"use strict";(self.webpackChunkrts_docs=self.webpackChunkrts_docs||[]).push([["7112"],{26444(e,t,n){n.r(t),n.d(t,{metadata:()=>o,default:()=>d,frontMatter:()=>i,contentTitle:()=>c,toc:()=>l,assets:()=>a});var o=JSON.parse('{"id":"cloud/hpc_bursting_to_cloud/intro","title":"HPC Bursting","description":"[gcp-cost-calculator]//cloudpricingcalculator.appspot.com/","source":"@site/docs/cloud/03_hpc_bursting_to_cloud/01_intro.md","sourceDirName":"cloud/03_hpc_bursting_to_cloud","slug":"/cloud/hpc_bursting_to_cloud/intro","permalink":"/docs/cloud/hpc_bursting_to_cloud/intro","draft":false,"unlisted":false,"editUrl":"https://github.com/NYU-RTS/rts-docs/blob/main/docs/cloud/03_hpc_bursting_to_cloud/01_intro.md","tags":[],"version":"current","sidebarPosition":1,"frontMatter":{},"sidebar":"cloudSidebar","previous":{"title":"NIH Strides","permalink":"/docs/cloud/gcp_self_managed/nih_strides"},"next":{"title":"Visualization Workstations","permalink":"/docs/cloud/hpc_bursting_to_cloud/visualization"}}'),s=n(62615),r=n(30416);let i={},c="HPC Bursting",a={},l=[{value:"Running a Bursting Job",id:"running-a-bursting-job",level:2},{value:"Access to Slurm Partitions",id:"access-to-slurm-partitions",level:2},{value:"Storage",id:"storage",level:3},{value:"Current Limits",id:"current-limits",level:3}];function u(e){let t={a:"a",admonition:"admonition",code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",p:"p",pre:"pre",...(0,r.R)(),...e.components};return(0,s.jsxs)(s.Fragment,{children:[(0,s.jsx)(t.header,{children:(0,s.jsx)(t.h1,{id:"hpc-bursting",children:"HPC Bursting"})}),"\n",(0,s.jsx)(t.p,{children:"HPC may provide bursting capabilities to researchers or classes, in some cases, in order to augment the available resources. Bursting is ideal for when you need a large amount of resources for a very short period of time. The way that bursting is made possible is by running a scalable SLURM cluster in the Google Cloud Platform (GCP), which is separate from the on-premise HPC clusters."}),"\n",(0,s.jsxs)(t.p,{children:["Bursting is not available to all users and requires advanced approval. In order to get access to these capabilities, please contact ",(0,s.jsx)(t.a,{href:"mailto:hpc@nyu.edu",children:"hpc@nyu.edu"})," to check your eligibility. Please let us know the amount of storage, total CPUs, Memory, GPU, the number of days you require access, and the estimated total CPU/GPU hours you will use. For reference, please review the ",(0,s.jsx)(t.a,{href:"https://cloudpricingcalculator.appspot.com/",children:"GCP cost calculator"}),". Please send a copy of your cost calculation to ",(0,s.jsx)(t.a,{href:"mailto:hpc@nyu.edu",children:"hpc@nyu.edu"})," as well."]}),"\n",(0,s.jsx)(t.admonition,{type:"tip",children:(0,s.jsxs)(t.p,{children:["To request access to the HPC Bursting capabilities, ",(0,s.jsx)(t.a,{href:"https://sites.google.com/nyu.edu/nyu-hpc/hpc-systems/cloud-computing/hpc-bursting-to-cloud/hpc-bursting-request-form?authuser=0",children:"please complete this form"}),"."]})}),"\n",(0,s.jsx)(t.h2,{id:"running-a-bursting-job",children:"Running a Bursting Job"}),"\n",(0,s.jsx)(t.admonition,{type:"note",children:(0,s.jsx)(t.p,{children:"This is not public, only per request of eligible classes or researchers"})}),"\n",(0,s.jsx)(t.pre,{children:(0,s.jsx)(t.code,{className:"language-sh",children:"ssh <NetID>@login.torch.hpc.nyu.edu\n"})}),"\n",(0,s.jsx)(t.p,{children:"ssh to the class on GCP (burst login node) - anyone can login but you can only submit jobs if you have approval"}),"\n",(0,s.jsx)(t.pre,{children:(0,s.jsx)(t.code,{className:"language-sh",children:"ssh burst \n"})}),"\n",(0,s.jsx)(t.p,{children:"Start an interactive job"}),"\n",(0,s.jsx)(t.pre,{children:(0,s.jsx)(t.code,{className:"language-sh",children:"srun --account=hpc --partition=interactive --pty /bin/bash\n"})}),"\n",(0,s.jsx)(t.p,{children:'If you got an error "Invalid account or account/partition combination specified" it means your account is not approved to use cloud bursting.'}),"\n",(0,s.jsx)(t.p,{children:"Once your files are copied to the bursting instance you can run a batch job from the interactive session."}),"\n",(0,s.jsx)(t.h2,{id:"access-to-slurm-partitions",children:"Access to Slurm Partitions"}),"\n",(0,s.jsx)(t.p,{children:'In the example above the partition "interactive" is used. You can list current partitions by running command'}),"\n",(0,s.jsx)(t.pre,{children:(0,s.jsx)(t.code,{className:"language-sh",children:"sinfo\n"})}),"\n",(0,s.jsxs)(t.p,{children:["However, approval is required to submit jobs to the partitions. Partitions are set up by the resources available to a job, such as the number of CPU, amount of memory, and number of GPUs. Please email ",(0,s.jsx)(t.a,{href:"mailto:hpc@nyu.edu",children:"hpc@nyu.edu"})," to request access to a specific partition or create a new partition (e.g. 10 CPUs and 64 GB Memory) for more optimal cost/performance of your job."]}),"\n",(0,s.jsx)(t.h3,{id:"storage",children:"Storage"}),"\n",(0,s.jsxs)(t.p,{children:["Torch's ",(0,s.jsx)(t.code,{children:"/home"})," and ",(0,s.jsx)(t.code,{children:"/scratch"})," are mounted (available) at login node of bursting setup."]}),"\n",(0,s.jsxs)(t.p,{children:["Compute node however, do have independent ",(0,s.jsx)(t.code,{children:"/home"})," and ",(0,s.jsx)(t.code,{children:"/scratch"}),".  These ",(0,s.jsx)(t.code,{children:"/home"})," and ",(0,s.jsx)(t.code,{children:"/scratch"})," mounts are persistent, are available from any compute node and independent from ",(0,s.jsx)(t.code,{children:"/home"})," and ",(0,s.jsx)(t.code,{children:"/scratch"})," at Torch."]}),"\n",(0,s.jsxs)(t.p,{children:["User may need to copy data from Torch's ",(0,s.jsx)(t.code,{children:"/home"})," or ",(0,s.jsx)(t.code,{children:"/scratch"})," to GCP mounted ",(0,s.jsx)(t.code,{children:"/home"})," or ",(0,s.jsx)(t.code,{children:"/scratch"})]}),"\n",(0,s.jsx)(t.p,{children:"When you run a bursting job the compute nodes will not see those file mounts. This means that you need to copy data to the burst instance."}),"\n",(0,s.jsx)(t.p,{children:"The file systems are independent, so you must copy data to the GCP location."}),"\n",(0,s.jsx)(t.p,{children:"To copy data, you must first start an interactive job. Once started, you can copy your data using scp from the HPC Data Transfer Nodes (torch-dtn). Below is the basic setup to copy files from Torch to your home directory while you are in an interactive bursting job:"}),"\n",(0,s.jsx)(t.pre,{children:(0,s.jsx)(t.code,{className:"language-sh",children:"scp <NetID>@dtn.torch.hpc.nyu.edu:/path/to/files /home/<NetID>/\n"})}),"\n",(0,s.jsx)(t.h3,{id:"current-limits",children:"Current Limits"}),"\n",(0,s.jsx)(t.p,{children:"20,000 CPUs available at any given time for all active bursting users"})]})}function d(e={}){let{wrapper:t}={...(0,r.R)(),...e.components};return t?(0,s.jsx)(t,{...e,children:(0,s.jsx)(u,{...e})}):u(e)}},30416(e,t,n){n.d(t,{R:()=>i,x:()=>c});var o=n(59471);let s={},r=o.createContext(s);function i(e){let t=o.useContext(r);return o.useMemo(function(){return"function"==typeof e?e(t):{...t,...e}},[t,e])}function c(e){let t;return t=e.disableParentContext?"function"==typeof e.components?e.components(s):e.components||s:i(e.components),o.createElement(r.Provider,{value:t},e.children)}}}]);