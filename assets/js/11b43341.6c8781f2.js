"use strict";(self.webpackChunkrts_docs=self.webpackChunkrts_docs||[]).push([["6745"],{15293(e){e.exports=JSON.parse('{"version":{"pluginId":"default","version":"current","label":"Next","banner":null,"badge":false,"noIndex":false,"className":"docs-version-current","isLast":true,"docsSidebars":{"genaiSidebar":[{"type":"category","label":"Getting Started","collapsible":true,"collapsed":true,"items":[{"type":"link","href":"/docs/genai/getting_started/intro","label":"Pythia","docId":"genai/getting_started/intro","unlisted":false},{"type":"link","href":"/docs/genai/getting_started/llm_gateway","label":"LLM Gateway","docId":"genai/getting_started/llm_gateway","unlisted":false}]},{"type":"category","label":"On-boarding & Setup","collapsible":true,"collapsed":true,"items":[{"type":"link","href":"/docs/genai/onboarding/intro","label":"Getting access","docId":"genai/onboarding/intro","unlisted":false},{"type":"link","href":"/docs/genai/onboarding/setup","label":"Setup","docId":"genai/onboarding/setup","unlisted":false},{"type":"link","href":"/docs/genai/onboarding/quickstart","label":"Quickstart","docId":"genai/onboarding/quickstart","unlisted":false}]},{"type":"category","label":"Access externally hosted LLMs","collapsible":true,"collapsed":true,"items":[{"type":"link","href":"/docs/genai/external_llms/catalogue","label":"LLM Catalogue","docId":"genai/external_llms/catalogue","unlisted":false},{"type":"link","href":"/docs/genai/external_llms/openwebui","label":"OpenWebUI","docId":"genai/external_llms/openwebui","unlisted":false}]},{"type":"category","label":"How to guides","collapsible":true,"collapsed":true,"items":[{"type":"link","href":"/docs/genai/how_to_guides/temperature","label":"Effect of Temperature","docId":"genai/how_to_guides/temperature","unlisted":false},{"type":"link","href":"/docs/genai/how_to_guides/embeddings","label":"Generating embeddings","docId":"genai/how_to_guides/embeddings","unlisted":false},{"type":"link","href":"/docs/genai/how_to_guides/retrieval_augmented_generation","label":"Retrieval-augmented generation","docId":"genai/how_to_guides/retrieval_augmented_generation","unlisted":false},{"type":"link","href":"/docs/genai/how_to_guides/llm_fine_tuning","label":"Fine tuning","docId":"genai/how_to_guides/llm_fine_tuning","unlisted":false}]}],"hpcSidebar":[{"type":"category","label":"Getting Started","collapsible":true,"collapsed":true,"items":[{"type":"link","href":"/docs/hpc/getting_started/intro","label":"Start here!","docId":"hpc/getting_started/intro","unlisted":false},{"type":"link","href":"/docs/hpc/getting_started/getting_and_renewing_an_account","label":"Getting and Renewing an Account","docId":"hpc/getting_started/getting_and_renewing_an_account","unlisted":false},{"type":"link","href":"/docs/hpc/getting_started/walkthrough_request_hpc_account","label":"How to request an HPC account","docId":"hpc/getting_started/walkthrough_request_hpc_account","unlisted":false},{"type":"link","href":"/docs/hpc/getting_started/walkthrough_approve_hpc_account_request","label":"How to approve an HPC Account Request","docId":"hpc/getting_started/walkthrough_approve_hpc_account_request","unlisted":false},{"type":"link","href":"/docs/hpc/getting_started/walkthrough_renew_hpc_account","label":"Renewing your HPC Account","docId":"hpc/getting_started/walkthrough_renew_hpc_account","unlisted":false},{"type":"link","href":"/docs/hpc/getting_started/hpc_accounts_external_collaborators","label":"HPC Accounts for Sponsored External Collaborators","docId":"hpc/getting_started/hpc_accounts_external_collaborators","unlisted":false},{"type":"link","href":"/docs/hpc/getting_started/hpc_project_management_portal","label":"HPC project management portal","docId":"hpc/getting_started/hpc_project_management_portal","unlisted":false},{"type":"link","href":"/docs/hpc/getting_started/creating_hpc_projects","label":"How to create a project on the HPC project management portal","docId":"hpc/getting_started/creating_hpc_projects","unlisted":false},{"type":"link","href":"/docs/hpc/getting_started/requesting_an_allocation","label":"Managing allocations for your project","docId":"hpc/getting_started/requesting_an_allocation","unlisted":false},{"type":"link","href":"/docs/hpc/getting_started/approving_an_allocation_request","label":"How to approve an allocation request","docId":"hpc/getting_started/approving_an_allocation_request","unlisted":false}]},{"type":"category","label":"Setup","collapsible":true,"collapsed":true,"items":[{"type":"link","href":"/docs/hpc/connecting_to_hpc/connecting_to_hpc","label":"Connecting to the HPC Cluster","docId":"hpc/connecting_to_hpc/connecting_to_hpc","unlisted":false},{"type":"link","href":"/docs/hpc/connecting_to_hpc/x11_forwarding","label":"X11 Forwarding","docId":"hpc/connecting_to_hpc/x11_forwarding","unlisted":false}]},{"type":"category","label":"Storage & Data transfers","collapsible":true,"collapsed":true,"items":[{"type":"link","href":"/docs/hpc/storage/intro_and_data_management","label":"HPC Storage","docId":"hpc/storage/intro_and_data_management","unlisted":false},{"type":"link","href":"/docs/hpc/storage/data_transfers","label":"Data Transfers","docId":"hpc/storage/data_transfers","unlisted":false},{"type":"link","href":"/docs/hpc/storage/globus","label":"Globus","docId":"hpc/storage/globus","unlisted":false},{"type":"link","href":"/docs/hpc/storage/research_project_space","label":"Research Project Space (RPS)","docId":"hpc/storage/research_project_space","unlisted":false},{"type":"link","href":"/docs/hpc/storage/best_practices","label":"Best Practices on HPC Storage","docId":"hpc/storage/best_practices","unlisted":false},{"type":"link","href":"/docs/hpc/storage/large_number_of_small_files","label":"Large Number of Small Files","docId":"hpc/storage/large_number_of_small_files","unlisted":false},{"type":"link","href":"/docs/hpc/storage/transferring_cloud_storage_data_with_rclone","label":"Transferring Cloud Storage Data with rclone","docId":"hpc/storage/transferring_cloud_storage_data_with_rclone","unlisted":false},{"type":"link","href":"/docs/hpc/storage/sharing_data_on_hpc","label":"Sharing Data on HPC","docId":"hpc/storage/sharing_data_on_hpc","unlisted":false}]},{"type":"category","label":"Datasets","collapsible":true,"collapsed":true,"items":[{"type":"link","href":"/docs/hpc/datasets/intro","label":"Datasets Available","docId":"hpc/datasets/intro","unlisted":false},{"type":"link","href":"/docs/hpc/datasets/working_with_datasets","label":"Working with Datasets","docId":"hpc/datasets/working_with_datasets","unlisted":false}]},{"type":"category","label":"Submitting jobs","collapsible":true,"collapsed":true,"items":[{"type":"link","href":"/docs/hpc/submitting_jobs/slurm_submitting_jobs","label":"Submitting Jobs on Torch","docId":"hpc/submitting_jobs/slurm_submitting_jobs","unlisted":false},{"type":"link","href":"/docs/hpc/submitting_jobs/slurm_main_commands","label":"Slurm: Command reference","docId":"hpc/submitting_jobs/slurm_main_commands","unlisted":false}]},{"type":"category","label":"Tools & Software","collapsible":true,"collapsed":true,"items":[{"type":"link","href":"/docs/hpc/tools_and_software/intro","label":"Start here!","docId":"hpc/tools_and_software/intro","unlisted":false},{"type":"link","href":"/docs/hpc/tools_and_software/licensed_software","label":"Licensed Software","docId":"hpc/tools_and_software/licensed_software","unlisted":false},{"type":"link","href":"/docs/hpc/tools_and_software/modules","label":"Modules","docId":"hpc/tools_and_software/modules","unlisted":false},{"type":"link","href":"/docs/hpc/tools_and_software/python_packages_with_virtual_environments","label":"Python Packages with Virtual Environments","docId":"hpc/tools_and_software/python_packages_with_virtual_environments","unlisted":false},{"type":"link","href":"/docs/hpc/tools_and_software/r_packages_with_renv","label":"R Packages with renv","docId":"hpc/tools_and_software/r_packages_with_renv","unlisted":false},{"type":"link","href":"/docs/hpc/tools_and_software/conda_environments","label":"Conda Environments (Python, R)","docId":"hpc/tools_and_software/conda_environments","unlisted":false},{"type":"link","href":"/docs/hpc/tools_and_software/sqlite_handling_large_structured_data","label":"SQLite: Handling Large Structured Data","docId":"hpc/tools_and_software/sqlite_handling_large_structured_data","unlisted":false}]},{"type":"category","label":"Containers","collapsible":true,"collapsed":true,"items":[{"type":"link","href":"/docs/hpc/containers/intro","label":"Custom Applications with Containers","docId":"hpc/containers/intro","unlisted":false},{"type":"link","href":"/docs/hpc/containers/containers","label":"Using Containers on HPC","docId":"hpc/containers/containers","unlisted":false},{"type":"link","href":"/docs/hpc/containers/singularity_with_conda","label":"Singularity with Conda","docId":"hpc/containers/singularity_with_conda","unlisted":false},{"type":"link","href":"/docs/hpc/containers/squash_file_system_and_singularity","label":"Squash File System and Singularity","docId":"hpc/containers/squash_file_system_and_singularity","unlisted":false}]},{"type":"category","label":"ML/AI on HPC","collapsible":true,"collapsed":true,"items":[{"type":"link","href":"/docs/hpc/ml_ai_hpc/intro","label":"Machine Learning (ML) and Artificial Intelligence (AI) on HPC","docId":"hpc/ml_ai_hpc/intro","unlisted":false},{"type":"link","href":"/docs/hpc/ml_ai_hpc/pytorch_intro","label":"Single-GPU Training with PyTorch","docId":"hpc/ml_ai_hpc/pytorch_intro","unlisted":false},{"type":"link","href":"/docs/hpc/ml_ai_hpc/pytorch_dpp","label":"Multi-GPU Training with PyTorch: Distributed Data Parallel (DDP)","docId":"hpc/ml_ai_hpc/pytorch_dpp","unlisted":false},{"type":"link","href":"/docs/hpc/ml_ai_hpc/tensorflow","label":"TensorFlow","docId":"hpc/ml_ai_hpc/tensorflow","unlisted":false},{"type":"link","href":"/docs/hpc/ml_ai_hpc/llm_fine_tuning","label":"Fine tune LLMs on HPC","docId":"hpc/ml_ai_hpc/llm_fine_tuning","unlisted":false},{"type":"category","label":"LLM Inference","collapsible":true,"collapsed":true,"items":[{"type":"link","href":"/docs/hpc/ml_ai_hpc/LLM Inference/run_hf_model","label":"Run a Hugging Face model","docId":"hpc/ml_ai_hpc/LLM Inference/run_hf_model","unlisted":false},{"type":"link","href":"/docs/hpc/ml_ai_hpc/LLM Inference/vLLM","label":"vLLM - A Command Line LLM Tool","docId":"hpc/ml_ai_hpc/LLM Inference/vLLM","unlisted":false},{"type":"link","href":"/docs/hpc/ml_ai_hpc/LLM Inference/llm_inferenceoverview","label":"Overview","docId":"hpc/ml_ai_hpc/LLM Inference/llm_inferenceoverview","unlisted":false}]}]},{"type":"category","label":"Open OnDemand (OOD)","collapsible":true,"collapsed":true,"items":[{"type":"link","href":"/docs/hpc/ood/ood_intro","label":"Introduction to Open OnDemand (OOD)","docId":"hpc/ood/ood_intro","unlisted":false},{"type":"link","href":"/docs/hpc/ood/CellACDC","label":"Cell-ACDC in OOD","docId":"hpc/ood/CellACDC","unlisted":false},{"type":"link","href":"/docs/hpc/ood/Dask","label":"Dask in Jupyter Notebook in OOD","docId":"hpc/ood/Dask","unlisted":false},{"type":"link","href":"/docs/hpc/ood/Desktop","label":"Desktop in OOD","docId":"hpc/ood/Desktop","unlisted":false},{"type":"link","href":"/docs/hpc/ood/igv","label":"Integrative Genomics Viewer (IGV) in OOD","docId":"hpc/ood/igv","unlisted":false},{"type":"link","href":"/docs/hpc/ood/jbrowse_genome_browser","label":"JBrowse Genome Browser in OOD","docId":"hpc/ood/jbrowse_genome_browser","unlisted":false},{"type":"link","href":"/docs/hpc/ood/jupyter_with_conda_singularity","label":"Jupyter Notebook with Conda/Singularity in OOD","docId":"hpc/ood/jupyter_with_conda_singularity","unlisted":false},{"type":"link","href":"/docs/hpc/ood/matlab_proxy","label":"Matlab-Proxy in OOD","docId":"hpc/ood/matlab_proxy","unlisted":false},{"type":"link","href":"/docs/hpc/ood/RStudio","label":"RStudio in OOD","docId":"hpc/ood/RStudio","unlisted":false},{"type":"link","href":"/docs/hpc/ood/Spark","label":"Spark Standalone Cluster with Jupyter Notebook in OOD","docId":"hpc/ood/Spark","unlisted":false},{"type":"link","href":"/docs/hpc/ood/Stata","label":"Stata in OOD","docId":"hpc/ood/Stata","unlisted":false}]},{"type":"link","href":"/docs/hpc/spec_sheet","label":"Torch Spec Sheet","docId":"hpc/spec_sheet","unlisted":false},{"type":"link","href":"/docs/hpc/system_status","label":"Greene System Status","docId":"hpc/system_status","unlisted":false},{"type":"category","label":"Tutorial: Intro to Shell for HPC","collapsible":true,"collapsed":true,"items":[{"type":"link","href":"/docs/hpc/tutorial_intro_shell_hpc/intro","label":"Introduction to Using the Shell on Torch","docId":"hpc/tutorial_intro_shell_hpc/intro","unlisted":false},{"type":"link","href":"/docs/hpc/tutorial_intro_shell_hpc/connecting_to_hpc","label":"Connecting to the remote HPC system Torch","docId":"hpc/tutorial_intro_shell_hpc/connecting_to_hpc","unlisted":false},{"type":"link","href":"/docs/hpc/tutorial_intro_shell_hpc/moving_looking","label":"Moving around and looking at things","docId":"hpc/tutorial_intro_shell_hpc/moving_looking","unlisted":false},{"type":"link","href":"/docs/hpc/tutorial_intro_shell_hpc/writing_reading_files","label":"Writing and Reading Files","docId":"hpc/tutorial_intro_shell_hpc/writing_reading_files","unlisted":false},{"type":"link","href":"/docs/hpc/tutorial_intro_shell_hpc/wildcards_pipes","label":"Wildcards and Pipes","docId":"hpc/tutorial_intro_shell_hpc/wildcards_pipes","unlisted":false},{"type":"link","href":"/docs/hpc/tutorial_intro_shell_hpc/scripts_variables_loops","label":"Scripts, variables, and loops","docId":"hpc/tutorial_intro_shell_hpc/scripts_variables_loops","unlisted":false}]},{"type":"category","label":"Tutorial: Intro to HPC","collapsible":true,"collapsed":true,"items":[{"type":"link","href":"/docs/hpc/tutorial_intro_hpc/intro_hpc","label":"Introduction to High-Performance Computing","docId":"hpc/tutorial_intro_hpc/intro_hpc","unlisted":false},{"type":"link","href":"/docs/hpc/tutorial_intro_hpc/why_use_cluster","label":"Why Use a Cluster?","docId":"hpc/tutorial_intro_hpc/why_use_cluster","unlisted":false},{"type":"link","href":"/docs/hpc/tutorial_intro_hpc/exploring_remote_resources","label":"Exploring Remote Resources","docId":"hpc/tutorial_intro_hpc/exploring_remote_resources","unlisted":false},{"type":"link","href":"/docs/hpc/tutorial_intro_hpc/scheduler_fundamentals","label":"Scheduler Fundamentals","docId":"hpc/tutorial_intro_hpc/scheduler_fundamentals","unlisted":false},{"type":"link","href":"/docs/hpc/tutorial_intro_hpc/environment_variables","label":"Environment Variables","docId":"hpc/tutorial_intro_hpc/environment_variables","unlisted":false},{"type":"link","href":"/docs/hpc/tutorial_intro_hpc/modules","label":"Accessing software via Modules","docId":"hpc/tutorial_intro_hpc/modules","unlisted":false},{"type":"link","href":"/docs/hpc/tutorial_intro_hpc/transferring_files_remote","label":"Transferring files with remote computers","docId":"hpc/tutorial_intro_hpc/transferring_files_remote","unlisted":false},{"type":"link","href":"/docs/hpc/tutorial_intro_hpc/running_parallel_job","label":"Running a parallel job","docId":"hpc/tutorial_intro_hpc/running_parallel_job","unlisted":false},{"type":"link","href":"/docs/hpc/tutorial_intro_hpc/using_resources_effectively","label":"Using resources effectively","docId":"hpc/tutorial_intro_hpc/using_resources_effectively","unlisted":false},{"type":"link","href":"/docs/hpc/tutorial_intro_hpc/using_resources_responsibly","label":"Using shared resources responsibly","docId":"hpc/tutorial_intro_hpc/using_resources_responsibly","unlisted":false}]},{"type":"category","label":"Support","collapsible":true,"collapsed":true,"items":[{"type":"link","href":"/docs/hpc/support/support","label":"Support","docId":"hpc/support/support","unlisted":false}]}],"cloudSidebar":[{"type":"category","label":"Getting Started","collapsible":true,"collapsed":true,"items":[{"type":"link","href":"/docs/cloud/getting_started/intro","label":"Start here!","docId":"cloud/getting_started/intro","unlisted":false}]},{"type":"category","label":"GCP self-managed projects","collapsible":true,"collapsed":true,"items":[{"type":"link","href":"/docs/cloud/gcp_self_managed/intro","label":"Google Cloud Platform for Research","docId":"cloud/gcp_self_managed/intro","unlisted":false},{"type":"link","href":"/docs/cloud/gcp_self_managed/nih_strides","label":"NIH Strides","docId":"cloud/gcp_self_managed/nih_strides","unlisted":false}]},{"type":"category","label":"HPC bursting to cloud","collapsible":true,"collapsed":true,"items":[{"type":"link","href":"/docs/cloud/hpc_bursting_to_cloud/intro","label":"HPC Bursting","docId":"cloud/hpc_bursting_to_cloud/intro","unlisted":false},{"type":"link","href":"/docs/cloud/hpc_bursting_to_cloud/visualization","label":"Visualization Workstations","docId":"cloud/hpc_bursting_to_cloud/visualization","unlisted":false}]},{"type":"category","label":"Dataproc","collapsible":true,"collapsed":true,"items":[{"type":"link","href":"/docs/cloud/dataproc/intro","label":"Dataproc","docId":"cloud/dataproc/intro","unlisted":false},{"type":"link","href":"/docs/cloud/dataproc/data_management","label":"Data management","docId":"cloud/dataproc/data_management","unlisted":false},{"type":"link","href":"/docs/cloud/dataproc/computation","label":"Computation","docId":"cloud/dataproc/computation","unlisted":false}]},{"type":"category","label":"Research Technology Cloud","collapsible":true,"collapsed":true,"items":[{"type":"link","href":"/docs/cloud/on_prem_cloud/intro","label":"Research Technology Cloud","docId":"cloud/on_prem_cloud/intro","unlisted":false}]}],"srdeSidebar":[{"type":"category","label":"Getting Started","collapsible":true,"collapsed":true,"items":[{"type":"link","href":"/docs/srde/getting_started/intro","label":"Start here!","docId":"srde/getting_started/intro","unlisted":false},{"type":"link","href":"/docs/srde/getting_started/eligibility_accounts","label":"Secure Research Data Environment (SRDE)","docId":"srde/getting_started/eligibility_accounts","unlisted":false}]},{"type":"category","label":"Frequently Asked Questions","collapsible":true,"collapsed":true,"items":[{"type":"link","href":"/docs/srde/faq/basics","label":"About SRDE, projects and getting started","docId":"srde/faq/basics","unlisted":false},{"type":"link","href":"/docs/srde/faq/env_roles","label":"Environment and Roles","docId":"srde/faq/env_roles","unlisted":false},{"type":"link","href":"/docs/srde/faq/using_srde","label":"Using the SRDE","docId":"srde/faq/using_srde","unlisted":false}]},{"type":"category","label":"Support","collapsible":true,"collapsed":true,"items":[{"type":"link","href":"/docs/srde/support/support","label":"Support","docId":"srde/support/support","unlisted":false}]},{"type":"category","label":"REDCap","collapsible":true,"collapsed":true,"items":[{"type":"link","href":"/docs/srde/redcap/redcap","label":"REDCap at NYU","docId":"srde/redcap/redcap","unlisted":false}]}]},"docs":{"cloud/dataproc/computation":{"id":"cloud/dataproc/computation","title":"Computation","description":"MapReduce","sidebar":"cloudSidebar"},"cloud/dataproc/data_management":{"id":"cloud/dataproc/data_management","title":"Data management","description":"HDFS stands for Hadoop Distributed File System. HDFS is a highly fault-tolerant file system and is designed to be deployed on low-cost hardware. HDFS provides high throughput access to application data and is suitable for analyses that use large datasets.","sidebar":"cloudSidebar"},"cloud/dataproc/intro":{"id":"cloud/dataproc/intro","title":"Dataproc","description":"[gcs]//cloud.google.com/storage?hl=en","sidebar":"cloudSidebar"},"cloud/gcp_self_managed/intro":{"id":"cloud/gcp_self_managed/intro","title":"Google Cloud Platform for Research","description":"[internet2-gcp]//internet2.edu/services/google-cloud-platform/","sidebar":"cloudSidebar"},"cloud/gcp_self_managed/nih_strides":{"id":"cloud/gcp_self_managed/nih_strides","title":"NIH Strides","description":"[nih-strides]//cloud.nih.gov/","sidebar":"cloudSidebar"},"cloud/getting_started/intro":{"id":"cloud/getting_started/intro","title":"Start here!","description":"We facilitate access to cloud computing resources (GCP) for research, HPC Bursting, visualization, data analysis (hadoop) and host an OpenShift Kubernetes cluster on-prem. Please proceed to the relevant section to know more about the offerings and how you could harness them.","sidebar":"cloudSidebar"},"cloud/hpc_bursting_to_cloud/intro":{"id":"cloud/hpc_bursting_to_cloud/intro","title":"HPC Bursting","description":"[gcp-cost-calculator]//cloudpricingcalculator.appspot.com/","sidebar":"cloudSidebar"},"cloud/hpc_bursting_to_cloud/visualization":{"id":"cloud/hpc_bursting_to_cloud/visualization","title":"Visualization Workstations","description":"[vnc-clients]//help.ubuntu.com/community/VNC/Clients","sidebar":"cloudSidebar"},"cloud/on_prem_cloud/intro":{"id":"cloud/on_prem_cloud/intro","title":"Research Technology Cloud","description":"We host an OpenShift kubernetes cluster on-prem that is in the process of being made available to researchers. Stay tuned for further updates.","sidebar":"cloudSidebar"},"genai/external_llms/catalogue":{"id":"genai/external_llms/catalogue","title":"LLM Catalogue","description":"We currently facilitate access to the following externally hosted LLMs:","sidebar":"genaiSidebar"},"genai/external_llms/openwebui":{"id":"genai/external_llms/openwebui","title":"OpenWebUI","description":"We are working on providing an NYU hosted instance of OpenWebUI. More details about this will be provided soon.","sidebar":"genaiSidebar"},"genai/getting_started/intro":{"id":"genai/getting_started/intro","title":"Pythia","description":"If you\'re looking to harness Generative AI for administrative or classroom use, please reach out to genai-support@nyu.edu","sidebar":"genaiSidebar"},"genai/getting_started/llm_gateway":{"id":"genai/getting_started/llm_gateway","title":"LLM Gateway","description":"Portkey is an enterprise-grade LLM gateway running on-prem:","sidebar":"genaiSidebar"},"genai/how_to_guides/embeddings":{"id":"genai/how_to_guides/embeddings","title":"Generating embeddings","description":"While Decoder-only LLMs gained massive popularity via their usage in chatbots, Encoder-only LLMs can be used for a wider variety of tasks. Decoder-only LLMs \\"generate\\" tokens (\\"text\\") one at a time probabalisticsally. Encoder-only LLMs on the other hand take text as their input, tokenize it and generate \\"embeddings\\" as their output. Here, we shall walk through a task of generating embeddings from a text snippet.","sidebar":"genaiSidebar"},"genai/how_to_guides/llm_fine_tuning":{"id":"genai/how_to_guides/llm_fine_tuning","title":"Fine tuning","description":"Please look into harnessing RAG before attempting to fine-tune a model. For open-weight models, you can use the HPC cluster to perform LoRA fine-tuning as described here.","sidebar":"genaiSidebar"},"genai/how_to_guides/retrieval_augmented_generation":{"id":"genai/how_to_guides/retrieval_augmented_generation","title":"Retrieval-augmented generation","description":"For an in-depth overview of RAG and Jupyter notebook examples, please access the source materials used for the 2025 FORC session on RAG at//github.com/NYU-RTS/rag-forc-2025","sidebar":"genaiSidebar"},"genai/how_to_guides/temperature":{"id":"genai/how_to_guides/temperature","title":"Effect of Temperature","description":"Generating text (or images) from LLMs is inherently probabilistic. However, as an end user you have many parameters at your disposal to tweak the behavior of LLMs. Of these, temperature is the most commonly used. Broadly, it controls the randomness of the generated text. A lower temperature produces more deterministic outputs, while a higher temperature produces more random \\"creative\\" output. For a more comprehensive explanation on this topic, refer to the following:","sidebar":"genaiSidebar"},"genai/onboarding/intro":{"id":"genai/onboarding/intro","title":"Getting access","description":"[research-workspace-request]//forms.gle/6DVA5dX4uPPrdX4Q9","sidebar":"genaiSidebar"},"genai/onboarding/quickstart":{"id":"genai/onboarding/quickstart","title":"Quickstart","description":"The machine sending requests to the LLM gateway needs to be connected to the NYU VPN to access the LLM gateway. If it is not connected to the VPN, your requests will timeout and result in connection errors.","sidebar":"genaiSidebar"},"genai/onboarding/setup":{"id":"genai/onboarding/setup","title":"Setup","description":"Accessing your workspace","sidebar":"genaiSidebar"},"hpc/connecting_to_hpc/connecting_to_hpc":{"id":"hpc/connecting_to_hpc/connecting_to_hpc","title":"Connecting to the HPC Cluster","description":"This page gives an overview of connecting to the HPC cluster, for a tutorial on this topic, head to the this section!","sidebar":"hpcSidebar"},"hpc/connecting_to_hpc/x11_forwarding":{"id":"hpc/connecting_to_hpc/x11_forwarding","title":"X11 Forwarding","description":"[xquartz]//www.xquartz.org/","sidebar":"hpcSidebar"},"hpc/containers/containers":{"id":"hpc/containers/containers","title":"Using Containers on HPC","description":"","sidebar":"hpcSidebar"},"hpc/containers/intro":{"id":"hpc/containers/intro","title":"Custom Applications with Containers","description":"What is Singularity?","sidebar":"hpcSidebar"},"hpc/containers/singularity_with_conda":{"id":"hpc/containers/singularity_with_conda","title":"Singularity with Conda","description":"Please note that Greene and Torch organize overlay files and Singularity images in different directories.","sidebar":"hpcSidebar"},"hpc/containers/squash_file_system_and_singularity":{"id":"hpc/containers/squash_file_system_and_singularity","title":"Squash File System and Singularity","description":"View available datasets on the Datasets page.","sidebar":"hpcSidebar"},"hpc/datasets/intro":{"id":"hpc/datasets/intro","title":"Datasets Available","description":"General","sidebar":"hpcSidebar"},"hpc/datasets/working_with_datasets":{"id":"hpc/datasets/working_with_datasets","title":"Working with Datasets","description":"Please see the Squash File System and Singularity page in the Containers section for details about working with datasets on the clusters.","sidebar":"hpcSidebar"},"hpc/getting_started/approving_an_allocation_request":{"id":"hpc/getting_started/approving_an_allocation_request","title":"How to approve an allocation request","description":"You need to be connected to the NYU VPN to access the  HPC project management portal.","sidebar":"hpcSidebar"},"hpc/getting_started/creating_hpc_projects":{"id":"hpc/getting_started/creating_hpc_projects","title":"How to create a project on the HPC project management portal","description":"You need to be connected to the NYU VPN to access the HPC project management portal.","sidebar":"hpcSidebar"},"hpc/getting_started/getting_and_renewing_an_account":{"id":"hpc/getting_started/getting_and_renewing_an_account","title":"Getting and Renewing an Account","description":"[nyu vpn link]//www.nyu.edu/life/information-technology/infrastructure/network-services/vpn.html","sidebar":"hpcSidebar"},"hpc/getting_started/hpc_accounts_external_collaborators":{"id":"hpc/getting_started/hpc_accounts_external_collaborators","title":"HPC Accounts for Sponsored External Collaborators","description":"External (non-NYU) collaborators can access, with proper sponsorship, the NYU HPC Environment.","sidebar":"hpcSidebar"},"hpc/getting_started/hpc_project_management_portal":{"id":"hpc/getting_started/hpc_project_management_portal","title":"HPC project management portal","description":"This section is only applicable to the Torch cluster. An active allocation is necessary to sumbmit jobs on Torch.","sidebar":"hpcSidebar"},"hpc/getting_started/intro":{"id":"hpc/getting_started/intro","title":"Start here!","description":"Welcome to the Torch HPC documentation! If you do not have an HPC account, please proceed to the next section that explains how you may be able to get one.","sidebar":"hpcSidebar"},"hpc/getting_started/requesting_an_allocation":{"id":"hpc/getting_started/requesting_an_allocation","title":"Managing allocations for your project","description":"You need to be connected to the NYU VPN to access the HPC project management portal.","sidebar":"hpcSidebar"},"hpc/getting_started/walkthrough_approve_hpc_account_request":{"id":"hpc/getting_started/walkthrough_approve_hpc_account_request","title":"How to approve an HPC Account Request","description":"When someone nominates you as their HPC sponsor, you should be notified by email.","sidebar":"hpcSidebar"},"hpc/getting_started/walkthrough_renew_hpc_account":{"id":"hpc/getting_started/walkthrough_renew_hpc_account","title":"Renewing your HPC Account","description":"You need to be on the NYU VPN to perform this task!","sidebar":"hpcSidebar"},"hpc/getting_started/walkthrough_request_hpc_account":{"id":"hpc/getting_started/walkthrough_request_hpc_account","title":"How to request an HPC account","description":"Make sure you don\'t already have an HPC account. You can check this by attempting to log in to the cluster, according to the instructions at Connecting to the HPC Cluster.","sidebar":"hpcSidebar"},"hpc/ml_ai_hpc/intro":{"id":"hpc/ml_ai_hpc/intro","title":"Machine Learning (ML) and Artificial Intelligence (AI) on HPC","description":"Many people are interested in running ML and/or AI workflows on the HPC resources.  To help facilitate this we have created this section that will provide examples of how one might use our resources for ML and AI tasks.","sidebar":"hpcSidebar"},"hpc/ml_ai_hpc/LLM Inference/llm_inferenceoverview":{"id":"hpc/ml_ai_hpc/LLM Inference/llm_inferenceoverview","title":"Overview","description":"This directory provides two primary pathways for deploying and running Large Language Models (LLMs) on the NYU Torch/Greene cluster: Hugging Face Transformers (for research/experimentation) and vLLM (for high-performance serving).","sidebar":"hpcSidebar"},"hpc/ml_ai_hpc/LLM Inference/run_hf_model":{"id":"hpc/ml_ai_hpc/LLM Inference/run_hf_model","title":"Run a Hugging Face model","description":"Here we provide an example of how one can run a Hugging Face Large-language model (LLM) on the NYU Torch cluster","sidebar":"hpcSidebar"},"hpc/ml_ai_hpc/LLM Inference/vLLM":{"id":"hpc/ml_ai_hpc/LLM Inference/vLLM","title":"vLLM - A Command Line LLM Tool","description":"What is vLLM?","sidebar":"hpcSidebar"},"hpc/ml_ai_hpc/llm_fine_tuning":{"id":"hpc/ml_ai_hpc/llm_fine_tuning","title":"Fine tune LLMs on HPC","description":"Model and Dataset Selection Rationale","sidebar":"hpcSidebar"},"hpc/ml_ai_hpc/pytorch_dpp":{"id":"hpc/ml_ai_hpc/pytorch_dpp","title":"Multi-GPU Training with PyTorch: Distributed Data Parallel (DDP)","description":"This was adapted from Princeton University Multi-GPU Training with PyTorch","sidebar":"hpcSidebar"},"hpc/ml_ai_hpc/pytorch_intro":{"id":"hpc/ml_ai_hpc/pytorch_intro","title":"Single-GPU Training with PyTorch","description":"This was adapted from Princeton University Multi-GPU Training with PyTorch","sidebar":"hpcSidebar"},"hpc/ml_ai_hpc/tensorflow":{"id":"hpc/ml_ai_hpc/tensorflow","title":"TensorFlow","description":"This was adapted from Princeton University Multi-GPU Training with PyTorch","sidebar":"hpcSidebar"},"hpc/ood/CellACDC":{"id":"hpc/ood/CellACDC","title":"Cell-ACDC in OOD","description":"Cell-ACDC is a GUI-based Python framework for segmentation, tracking, cell cycle annotations and quantification of microscopy data.","sidebar":"hpcSidebar"},"hpc/ood/Dask":{"id":"hpc/ood/Dask","title":"Dask in Jupyter Notebook in OOD","description":"Dask is a Python library for parallel and distributed computing.","sidebar":"hpcSidebar"},"hpc/ood/Desktop":{"id":"hpc/ood/Desktop","title":"Desktop in OOD","description":"You can get a basic desktop interface to HPC resources.","sidebar":"hpcSidebar"},"hpc/ood/igv":{"id":"hpc/ood/igv","title":"Integrative Genomics Viewer (IGV) in OOD","description":"The IGV is a high-performance, easy-to-use, interactive tool for the visual exploration of genomic data.","sidebar":"hpcSidebar"},"hpc/ood/jbrowse_genome_browser":{"id":"hpc/ood/jbrowse_genome_browser","title":"JBrowse Genome Browser in OOD","description":"JBrowse is a web-based genome browser for visualizing genomic features in common file formats, such as variants (VCF), genes (GFF3, BigBed) and gene expression (BigWig), and sequence alignments (BAM, CRAM, and GFF3).","sidebar":"hpcSidebar"},"hpc/ood/jupyter_with_conda_singularity":{"id":"hpc/ood/jupyter_with_conda_singularity","title":"Jupyter Notebook with Conda/Singularity in OOD","description":"Please note that Greene and Torch organize overlay files and Singularity images in different directories.","sidebar":"hpcSidebar"},"hpc/ood/matlab_proxy":{"id":"hpc/ood/matlab_proxy","title":"Matlab-Proxy in OOD","description":"Getting Started","sidebar":"hpcSidebar"},"hpc/ood/ood_intro":{"id":"hpc/ood/ood_intro","title":"Introduction to Open OnDemand (OOD)","description":"A Web-based Graphical User Interface","sidebar":"hpcSidebar"},"hpc/ood/RStudio":{"id":"hpc/ood/RStudio","title":"RStudio in OOD","description":"Getting Started","sidebar":"hpcSidebar"},"hpc/ood/Spark":{"id":"hpc/ood/Spark","title":"Spark Standalone Cluster with Jupyter Notebook in OOD","description":"Getting Started","sidebar":"hpcSidebar"},"hpc/ood/Stata":{"id":"hpc/ood/Stata","title":"Stata in OOD","description":"Getting Started","sidebar":"hpcSidebar"},"hpc/spec_sheet":{"id":"hpc/spec_sheet","title":"Torch Spec Sheet","description":"The Torch cluster has 518 Intel \\"Xeon Platinum 8592+ 64C\\" CPUs, 29 NVIDIA H200 GPUs & 68 NVIDIA L40S GPUs connected together via Infiniband NDR400 interconnect. Further details on each kind of node is provided in the table below.","sidebar":"hpcSidebar"},"hpc/storage/best_practices":{"id":"hpc/storage/best_practices","title":"Best Practices on HPC Storage","description":"User Quota Limits and the myquota command","sidebar":"hpcSidebar"},"hpc/storage/data_transfers":{"id":"hpc/storage/data_transfers","title":"Data Transfers","description":"Globus is the recommended tool to use for large-volume data transfers due to the efficiency, reliability, security and ease of use. Use other tools only if you really need to. Detailed instructions available at Globus","sidebar":"hpcSidebar"},"hpc/storage/globus":{"id":"hpc/storage/globus","title":"Globus","description":"The Globus project aims at providing powerful tools for scientific data management, to help researchers to focus on their domain subjects and solve data intensive research problems. Globus has been grown maturely to enable grid computing by connecting computing resources distributed globally across organizational boundary. Universities, national laboratories and computing facilities are using services of Globus.","sidebar":"hpcSidebar"},"hpc/storage/intro_and_data_management":{"id":"hpc/storage/intro_and_data_management","title":"HPC Storage","description":"-   High Risk data, such as those that include Personal Identifiable Information (PII) or electronic Protected Health Information (ePHI) or Controlled Unclassified Information (CUI) should NOT be stored in the HPC Environment. We recommend using the Secure Research Data Environments (SRDE) instead for this.","sidebar":"hpcSidebar"},"hpc/storage/large_number_of_small_files":{"id":"hpc/storage/large_number_of_small_files","title":"Large Number of Small Files","description":"Motivation","sidebar":"hpcSidebar"},"hpc/storage/research_project_space":{"id":"hpc/storage/research_project_space","title":"Research Project Space (RPS)","description":"Description","sidebar":"hpcSidebar"},"hpc/storage/sharing_data_on_hpc":{"id":"hpc/storage/sharing_data_on_hpc","title":"Sharing Data on HPC","description":"Introduction","sidebar":"hpcSidebar"},"hpc/storage/transferring_cloud_storage_data_with_rclone":{"id":"hpc/storage/transferring_cloud_storage_data_with_rclone","title":"Transferring Cloud Storage Data with rclone","description":"Globus is the recommended tool to use for large-volume data transfers due to the efficiency, reliability, security and ease of use. Use other tools only if you really need to. Detailed instructions available at Globus","sidebar":"hpcSidebar"},"hpc/submitting_jobs/slurm_main_commands":{"id":"hpc/submitting_jobs/slurm_main_commands","title":"Slurm: Command reference","description":"Slurm offers many utility commands to work with, some of the most popularly used commands are:","sidebar":"hpcSidebar"},"hpc/submitting_jobs/slurm_submitting_jobs":{"id":"hpc/submitting_jobs/slurm_submitting_jobs","title":"Submitting Jobs on Torch","description":"If you are new to using HPC resources and would like to learn about the principles of using the SLURM scheduler for submitting batch jobs, please refer to this section. This section focuses on the specifics of the Torch cluster and assumes familiarity with the tutorial.","sidebar":"hpcSidebar"},"hpc/support/support":{"id":"hpc/support/support","title":"Support","description":"-   Some of your questions may be already answered here","sidebar":"hpcSidebar"},"hpc/system_status":{"id":"hpc/system_status","title":"Greene System Status","description":"To be able to see the panels below you need to be within NYU network (use VPN if you are not on campus)","sidebar":"hpcSidebar"},"hpc/tools_and_software/conda_environments":{"id":"hpc/tools_and_software/conda_environments","title":"Conda Environments (Python, R)","description":"This page describes how you can create conda environments without containers in $SCRATCH//home/$USER. We strongly encourage you to create conda environments within Overlay files attached to Apptainer containers as described in this section. Please note that creating both kinds of conda environments is strongly discouraged as it leads to packages from one environment being accidentally used in another.","sidebar":"hpcSidebar"},"hpc/tools_and_software/intro":{"id":"hpc/tools_and_software/intro","title":"Start here!","description":"We encourage you to setup your own computational environment on Torch and to assist you in doing so, we allow you to run Apptainer (formerly known as Singularity) containers, we manage licensed software suites and offer extensive documentation, training and support.","sidebar":"hpcSidebar"},"hpc/tools_and_software/licensed_software":{"id":"hpc/tools_and_software/licensed_software","title":"Licensed Software","description":"SCHRODINGER","sidebar":"hpcSidebar"},"hpc/tools_and_software/modules":{"id":"hpc/tools_and_software/modules","title":"Modules","description":"Lmod, an Environment Module system, is a tool for managing multiple versions and configurations of software packages and is used by many HPC centers around the world. With Environment Modules, software packages are installed away from the base system directories, and for each package, an associated modulefile describes what must be altered in a user\'s shell environment - such as the $PATH environment variable - in order to use the software package. The modulefile also describes dependencies and conflicts between this software package and other packages and versions.","sidebar":"hpcSidebar"},"hpc/tools_and_software/python_packages_with_virtual_environments":{"id":"hpc/tools_and_software/python_packages_with_virtual_environments","title":"Python Packages with Virtual Environments","description":"This page describes how you can create virtual environments without containers in $SCRATCH//home/$USER. We strongly encourage you to create your computational environments within Overlay files attached to Apptainer containers as described in this section. Please note that creating both kinds of conda environments is strongly discouraged as it leads to packages from one environment being accidentally used in another.","sidebar":"hpcSidebar"},"hpc/tools_and_software/r_packages_with_renv":{"id":"hpc/tools_and_software/r_packages_with_renv","title":"R Packages with renv","description":"Is this needed:","sidebar":"hpcSidebar"},"hpc/tools_and_software/sqlite_handling_large_structured_data":{"id":"hpc/tools_and_software/sqlite_handling_large_structured_data","title":"SQLite: Handling Large Structured Data","description":"Overview","sidebar":"hpcSidebar"},"hpc/tutorial_intro_hpc/environment_variables":{"id":"hpc/tutorial_intro_hpc/environment_variables","title":"Environment Variables","description":"Questions","sidebar":"hpcSidebar"},"hpc/tutorial_intro_hpc/exploring_remote_resources":{"id":"hpc/tutorial_intro_hpc/exploring_remote_resources","title":"Exploring Remote Resources","description":"Questions","sidebar":"hpcSidebar"},"hpc/tutorial_intro_hpc/intro_hpc":{"id":"hpc/tutorial_intro_hpc/intro_hpc","title":"Introduction to High-Performance Computing","description":"This tutorial is an introduction to using the Torch high-performance computing systems at NYU effectively. It is not intended to be an exhaustive course on parallel programming.  The goal is to give new users of Torch an introduction and overview of the tools available and how to use them effectively.","sidebar":"hpcSidebar"},"hpc/tutorial_intro_hpc/modules":{"id":"hpc/tutorial_intro_hpc/modules","title":"Accessing software via Modules","description":"Questions","sidebar":"hpcSidebar"},"hpc/tutorial_intro_hpc/running_parallel_job":{"id":"hpc/tutorial_intro_hpc/running_parallel_job","title":"Running a parallel job","description":"Questions","sidebar":"hpcSidebar"},"hpc/tutorial_intro_hpc/scheduler_fundamentals":{"id":"hpc/tutorial_intro_hpc/scheduler_fundamentals","title":"Scheduler Fundamentals","description":"Questions","sidebar":"hpcSidebar"},"hpc/tutorial_intro_hpc/transferring_files_remote":{"id":"hpc/tutorial_intro_hpc/transferring_files_remote","title":"Transferring files with remote computers","description":"Questions","sidebar":"hpcSidebar"},"hpc/tutorial_intro_hpc/using_resources_effectively":{"id":"hpc/tutorial_intro_hpc/using_resources_effectively","title":"Using resources effectively","description":"Questions","sidebar":"hpcSidebar"},"hpc/tutorial_intro_hpc/using_resources_responsibly":{"id":"hpc/tutorial_intro_hpc/using_resources_responsibly","title":"Using shared resources responsibly","description":"Questions","sidebar":"hpcSidebar"},"hpc/tutorial_intro_hpc/why_use_cluster":{"id":"hpc/tutorial_intro_hpc/why_use_cluster","title":"Why Use a Cluster?","description":"Questions","sidebar":"hpcSidebar"},"hpc/tutorial_intro_shell_hpc/connecting_to_hpc":{"id":"hpc/tutorial_intro_shell_hpc/connecting_to_hpc","title":"Connecting to the remote HPC system Torch","description":"Questions:","sidebar":"hpcSidebar"},"hpc/tutorial_intro_shell_hpc/intro":{"id":"hpc/tutorial_intro_shell_hpc/intro","title":"Introduction to Using the Shell on Torch","description":"This tutorial is an introduction to using the high-performance computing resources on Torch.  It is intended to give users a good introduction and overview of the tools available and how to use them effectively.","sidebar":"hpcSidebar"},"hpc/tutorial_intro_shell_hpc/moving_looking":{"id":"hpc/tutorial_intro_shell_hpc/moving_looking","title":"Moving around and looking at things","description":"Questions","sidebar":"hpcSidebar"},"hpc/tutorial_intro_shell_hpc/scripts_variables_loops":{"id":"hpc/tutorial_intro_shell_hpc/scripts_variables_loops","title":"Scripts, variables, and loops","description":"Questions","sidebar":"hpcSidebar"},"hpc/tutorial_intro_shell_hpc/wildcards_pipes":{"id":"hpc/tutorial_intro_shell_hpc/wildcards_pipes","title":"Wildcards and Pipes","description":"Questions","sidebar":"hpcSidebar"},"hpc/tutorial_intro_shell_hpc/writing_reading_files":{"id":"hpc/tutorial_intro_shell_hpc/writing_reading_files","title":"Writing and Reading Files","description":"Questions","sidebar":"hpcSidebar"},"srde/faq/basics":{"id":"srde/faq/basics","title":"About SRDE, projects and getting started","description":"What is the SRDE?","sidebar":"srdeSidebar"},"srde/faq/env_roles":{"id":"srde/faq/env_roles","title":"Environment and Roles","description":"Who is the Data Steward?","sidebar":"srdeSidebar"},"srde/faq/using_srde":{"id":"srde/faq/using_srde","title":"Using the SRDE","description":"Will I receive training on how to use the SRDE?","sidebar":"srdeSidebar"},"srde/getting_started/eligibility_accounts":{"id":"srde/getting_started/eligibility_accounts","title":"Secure Research Data Environment (SRDE)","description":"The Secure Research Data Environment (SRDE) is a centralized secure computing platform designed to support research projects that require storage and computational resources.  It provides a space for researchers to design and build secure, scalable, and resilient environments to store, share, and analyze moderate and high-risk data, as per the NYU Electronic Data and System Risk Classification Policy.","sidebar":"srdeSidebar"},"srde/getting_started/intro":{"id":"srde/getting_started/intro","title":"Start here!","description":"Welcome to the Secure Research Data Environment documentation! If you do not have an active project, please proceed to the next section that explains the eligibility criteria and how you may request one.","sidebar":"srdeSidebar"},"srde/redcap/redcap":{"id":"srde/redcap/redcap","title":"REDCap at NYU","description":"REDCap is a Research Electronic Data Capture tool, originally developed in Vanderbilt University. The REDCap Consortium, composed of many active institutional partners from overall the world, utilizes and supports the REDCap ecosystem.","sidebar":"srdeSidebar"},"srde/support/support":{"id":"srde/support/support","title":"Support","description":"Please email your questions to: srde-support@nyu.edu","sidebar":"srdeSidebar"}}}}')}}]);