"use strict";(self.webpackChunkrts_docs=self.webpackChunkrts_docs||[]).push([["5093"],{14691(e,t,n){n.r(t),n.d(t,{metadata:()=>o,default:()=>u,frontMatter:()=>s,contentTitle:()=>i,toc:()=>d,assets:()=>l});var o=JSON.parse('{"id":"hpc/ood/Spark","title":"Spark Standalone Cluster with Jupyter Notebook in OOD","description":"Getting Started","source":"@site/docs/hpc/09_ood/10_Spark.mdx","sourceDirName":"hpc/09_ood","slug":"/hpc/ood/Spark","permalink":"/docs/hpc/ood/Spark","draft":false,"unlisted":false,"editUrl":"https://github.com/NYU-RTS/rts-docs/blob/main/docs/hpc/09_ood/10_Spark.mdx","tags":[],"version":"current","sidebarPosition":10,"frontMatter":{},"sidebar":"hpcSidebar","previous":{"title":"RStudio in OOD","permalink":"/docs/hpc/ood/RStudio"},"next":{"title":"Stata in OOD","permalink":"/docs/hpc/ood/Stata"}}'),r=n(62615),a=n(30416);let s={},i="Spark Standalone Cluster with Jupyter Notebook in OOD",l={},d=[{value:"Getting Started",id:"getting-started",level:2},{value:"Configuration",id:"configuration",level:2},{value:"Spark Standalone Cluster with Jupyter Notebook running in OOD",id:"spark-standalone-cluster-with-jupyter-notebook-running-in-ood",level:2},{value:"Spark Standalone Cluster Jupyter Notebook Example",id:"spark-standalone-cluster-jupyter-notebook-example",level:3}];function c(e){let t={a:"a",admonition:"admonition",code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",img:"img",li:"li",p:"p",pre:"pre",ul:"ul",...(0,a.R)(),...e.components};return(0,r.jsxs)(r.Fragment,{children:[(0,r.jsx)(t.header,{children:(0,r.jsx)(t.h1,{id:"spark-standalone-cluster-with-jupyter-notebook-in-ood",children:"Spark Standalone Cluster with Jupyter Notebook in OOD"})}),"\n",(0,r.jsx)(t.h2,{id:"getting-started",children:"Getting Started"}),"\n",(0,r.jsxs)(t.p,{children:["You can run a Spark Standalone Cluster with Jupyter Notebook in OOD by going to the URL ",(0,r.jsx)(t.a,{href:"http://ood.torch.hpc.nyu.edu",children:"ood.torch.hpc.nyu.edu"})," in your browser and selecting ",(0,r.jsx)(t.code,{children:"Spark Standalone Cluster"})," from the ",(0,r.jsx)(t.code,{children:"Interactive Apps"})," pull-down menu at the top of the page.  Once you've used it and other interactive apps they'll show up on your home screen under the ",(0,r.jsx)(t.code,{children:"Recently Used Apps"})," header."]}),"\n",(0,r.jsx)(t.admonition,{type:"note",children:(0,r.jsxs)(t.p,{children:["Be aware that when you start from ",(0,r.jsx)(t.code,{children:"Recently Used Apps"})," it will start with the same configuration that you used previously.  If you'd like to configure your Spark Standalone Cluster with Jupyter Notebook session differently, you'll need to select it from the menu."]})}),"\n",(0,r.jsx)(t.h2,{id:"configuration",children:"Configuration"}),"\n",(0,r.jsx)(t.p,{children:"You can select the Spark version, amount of time, number of nodes and cores, amount of memory, gpu type (if any), Jupyter notebook root directory, path to custom pyspark overlay (if any), and optional Slurm options."}),"\n",(0,r.jsx)(t.p,{children:(0,r.jsx)(t.img,{alt:"OOD Spark Configuration",src:n(72270).A+"",width:"896",height:"1816"})}),"\n",(0,r.jsx)(t.admonition,{type:"warning",children:(0,r.jsxs)(t.p,{children:["If you select to use ",(0,r.jsx)(t.code,{children:"/home"})," as your root directory be careful not to go over your quota.  You can find your current usage with the ",(0,r.jsx)(t.code,{children:"myquota"})," command.  Please see our ",(0,r.jsx)(t.a,{href:"/docs/hpc/storage/intro_and_data_management",children:"Storage documentation"})," for details about your storage options."]})}),"\n",(0,r.jsx)(t.h2,{id:"spark-standalone-cluster-with-jupyter-notebook-running-in-ood",children:"Spark Standalone Cluster with Jupyter Notebook running in OOD"}),"\n",(0,r.jsxs)(t.p,{children:["After you hit the ",(0,r.jsx)(t.code,{children:"Launch"})," button you'll have to wait for the scheduler to find node(s) for you to run on:\n",(0,r.jsx)(t.img,{alt:"OOD Spark in queue",src:n(99789).A+"",width:"1210",height:"560"})]}),"\n",(0,r.jsxs)(t.p,{children:["Then you'll have a short wait for Spark itself to start up.",(0,r.jsx)("br",{}),"\nOnce that happens you'll get one last page that will give you links to:"]}),"\n",(0,r.jsxs)(t.ul,{children:["\n",(0,r.jsx)(t.li,{children:"open a terminal window on the compute node your Spark session is running on"}),"\n",(0,r.jsx)(t.li,{children:"go to the directory associated with your Session ID that stores output, config and other related files for your session"}),"\n"]}),"\n",(0,r.jsx)(t.p,{children:(0,r.jsx)(t.img,{alt:"Pre-launch Spark OOD",src:n(42936).A+"",width:"1204",height:"710"})}),"\n",(0,r.jsxs)(t.p,{children:["Please click the ",(0,r.jsx)(t.code,{children:"Connect to the Jupyter Notebook Environment"})," button and a Jupyter window will open.  Please select to create a new notebook and you're ready to go."]}),"\n",(0,r.jsx)(t.h3,{id:"spark-standalone-cluster-jupyter-notebook-example",children:"Spark Standalone Cluster Jupyter Notebook Example"}),"\n",(0,r.jsxs)(t.p,{children:["Please enter the following commands into the first cell of your Jupyter notebook and execute them by typing ",(0,r.jsx)(t.code,{children:"Shift"})," and ",(0,r.jsx)(t.code,{children:"Enter"})," at the same time."]}),"\n",(0,r.jsx)(t.pre,{children:(0,r.jsx)(t.code,{className:"language-python",children:'from pyspark import SparkContext\nimport requests\n\n# Create a SparkContext\nsc = SparkContext("local", "WordCountExample")\n\n# Get text of Moby Dick from Project Gutenberg\nfile_url = \'https://www.gutenberg.org/ebooks/2701.txt.utf-8\'\ntry:\n    response = requests.get(file_url)\n    response.raise_for_status()\nexcept requests.exceptions.RequestException as e:\n    print(f"Error during request: {e}")\n# Save text to temp file\nwith open(\'moby_dick_temp_spark_example.txt\', "w") as file:\n    file.write(response.text)\n\n# Create an RDD from a text file\nlines = sc.textFile("/scratch/rjy1/moby_dick_temp_spark_example.txt")\n\n# FlatMap to split lines into words and convert to lowercase\nwords = lines.flatMap(lambda line: line.lower().split(" "))\n\n# Map each word to a (word, 1) tuple\nword_pairs = words.map(lambda word: (word, 1))\n\n# ReduceByKey to sum the counts for each word\nword_counts = word_pairs.reduceByKey(lambda a, b: a + b)\n\n# Collect the results to the driver program\nresults = word_counts.collect()\n\n# Print the word counts\nfor word, count in results:\n    print(f"{word}: {count}")\n'})}),"\n",(0,r.jsx)(t.p,{children:"You should get output like:"}),"\n",(0,r.jsx)(t.pre,{children:(0,r.jsx)(t.code,{children:"the: 14512\nproject: 87\ngutenberg: 25\nebook: 8\nof: 6682\nmoby: 81\ndick;: 10\nor,: 17\nwhale: 533\n: 4318\nthis: 1277\nis: 1601\nfor: 1555\nuse: 39\nanyone: 5\nanywhere: 11\nin: 4126\nunited: 24\nstates: 13\nand: 6321\nmost: 284\nother: 360\nparts: 32\nworld: 79\nat: 1310\nno: 488\ncost: 3\nwith: 1750\nalmost: 189\nrestrictions: 2\nwhatsoever.: 5\nyou: 843\nmay: 227\ncopy: 15\n...\n"})}),"\n",(0,r.jsx)(t.p,{children:"etc."})]})}function u(e={}){let{wrapper:t}={...(0,a.R)(),...e.components};return t?(0,r.jsx)(t,{...e,children:(0,r.jsx)(c,{...e})}):c(e)}},72270(e,t,n){n.d(t,{A:()=>o});let o=n.p+"assets/images/ood_spark_config-046f86598a995bc5dfca8af76c932ead.png"},99789(e,t,n){n.d(t,{A:()=>o});let o=n.p+"assets/images/ood_spark_in_queue-1d79d811d50c2e8b966491109281f842.png"},42936(e,t,n){n.d(t,{A:()=>o});let o=n.p+"assets/images/ood_spark_prelaunch-f500ae81a259132628f66a736ece2d41.png"},30416(e,t,n){n.d(t,{R:()=>s,x:()=>i});var o=n(59471);let r={},a=o.createContext(r);function s(e){let t=o.useContext(a);return o.useMemo(function(){return"function"==typeof e?e(t):{...t,...e}},[t,e])}function i(e){let t;return t=e.disableParentContext?"function"==typeof e.components?e.components(r):e.components||r:s(e.components),o.createElement(a.Provider,{value:t},e.children)}}}]);