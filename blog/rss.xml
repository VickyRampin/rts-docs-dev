<?xml version="1.0" encoding="utf-8"?><?xml-stylesheet type="text/xsl" href="rss.xsl"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/">
    <channel>
        <title>Connecting researchers to computational resources. Blog</title>
        <link>https://services.rt.nyu.edu/blog/</link>
        <description>Connecting researchers to computational resources. Blog</description>
        <lastBuildDate>Wed, 10 Sep 2025 00:00:00 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>en</language>
        <item>
            <title><![CDATA[Claude is now available]]></title>
            <link>https://services.rt.nyu.edu/blog/2025-09-10-claude/</link>
            <guid>https://services.rt.nyu.edu/blog/2025-09-10-claude/</guid>
            <pubDate>Wed, 10 Sep 2025 00:00:00 GMT</pubDate>
            <description><![CDATA[We are pleased to announce that the claude (4.0 and 3.7) models are now available via Pythia. Here are the overviews for the models:]]></description>
            <content:encoded><![CDATA[<p>We are pleased to announce that the <code>claude</code> (<code>4.0</code> and <code>3.7</code>) models are now available via Pythia. Here are the overviews for the models:
<a href="https://www.anthropic.com/claude/sonnet" target="_blank" rel="noopener noreferrer" class="">https://www.anthropic.com/claude/sonnet</a>, <a href="https://www.anthropic.com/claude/opus" target="_blank" rel="noopener noreferrer" class="">https://www.anthropic.com/claude/opus</a></p>
<p>With API keys to access Claude, you can also enable Claude API tools like Claude Code. Refer to this guide for more details: <a href="https://portkey.ai/docs/integrations/libraries/claude-code#2-integrate-portkey-with-claude-code" target="_blank" rel="noopener noreferrer" class="">https://portkey.ai/docs/integrations/libraries/claude-code#2-integrate-portkey-with-claude-code</a></p>]]></content:encoded>
            <category>Pythia</category>
            <category>GenAI</category>
        </item>
        <item>
            <title><![CDATA[o4-mini is now available]]></title>
            <link>https://services.rt.nyu.edu/blog/2025-05-02-o4-mini/</link>
            <guid>https://services.rt.nyu.edu/blog/2025-05-02-o4-mini/</guid>
            <pubDate>Fri, 02 May 2025 00:00:00 GMT</pubDate>
            <description><![CDATA[We are pleased to announce that o4-mini is now available via Pythia. Here is an overview of the model//platform.openai.com/docs/models/o4-mini]]></description>
            <content:encoded><![CDATA[<p>We are pleased to announce that <code>o4-mini</code> is now available via Pythia. Here is an overview of the model: <a href="https://platform.openai.com/docs/models/o4-mini" target="_blank" rel="noopener noreferrer" class="">https://platform.openai.com/docs/models/o4-mini</a></p>
<p>When compared to <code>o3-mini</code>, <code>o4-mini</code> adds support for images as inputs. It costs the same as o3-mini for regular usage, though the price is lower if you use cached inputs. Thus, this model will now be the default reasoning model we provide and the use of o3-mini is now deprecated.</p>]]></content:encoded>
            <category>Pythia</category>
            <category>GenAI</category>
        </item>
    </channel>
</rss>